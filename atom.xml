<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CRJ</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sssmeb.github.io/"/>
  <updated>2019-08-15T08:55:57.537Z</updated>
  <id>https://sssmeb.github.io/</id>
  
  <author>
    <name>CAO RUNJIA</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关于数据库索引</title>
    <link href="https://sssmeb.github.io/2019/08/09/%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"/>
    <id>https://sssmeb.github.io/2019/08/09/关于数据库索引/</id>
    <published>2019-08-09T08:25:26.000Z</published>
    <updated>2019-08-15T08:55:57.537Z</updated>
    
    <content type="html"><![CDATA[<h1 id="索引基础"><a href="#索引基础" class="headerlink" title="索引基础"></a>索引基础</h1><p>索引的作用是：</p><ul><li><strong>加速查找</strong></li><li><strong>约束</strong></li></ul><p><strong>索引优化是对查询性能优化最有效的手段</strong>了。索引能轻易将查询性能提高几个数量级，最优的索引有时比一个好的索引性能要好两个数量级。</p><p>如果没有使用索引，相当于从前往后整个表进行查找。而使用索引，相当于拥有了一个目录，可以大大加速查找。</p><p>创建索引的过程可以理解为数据库额外创建了一个文件（某种格式存储），作为目录。在查找时，先在这个目录中查找。即存储引擎先再索引中找到对应值，然后根据匹配的索引记录找到对应的数据行。</p><p>举例：</p><pre><code># 一开始name列没有索引select * from userinfo3 where name=&apos;alxe&apos;;    // 300w数据里 接近7s找到# 为name列创建一个普通的索引 相当于创建了一个目录文件create index ix_name on userinfo3(name);# 再次执行同样的查找select * from userinfo3 where name=&apos;alxe&apos;;   // 仅0.07秒就可以完成# 删除索引 使用 drop idex 索引名 on 表名</code></pre><h2 id="索引的种类"><a href="#索引的种类" class="headerlink" title="索引的种类"></a>索引的种类</h2><ul><li>普通索引 <ul><li>加速查找</li></ul></li><li>主键索引 <ul><li>加速查找 + 不能为空 + 不能重复</li></ul></li><li>唯一索引 <ul><li>加速查找 + 不能重复</li></ul></li><li>组合索引 <ul><li>多列组成一个索引<ul><li>联合主键索引</li><li>联合唯一索引</li><li>联合普通索引</li></ul></li></ul></li></ul><p>以及两种特殊索引名词</p><ul><li>（覆盖索引）能直接在索引文件获取到数据<ul><li>select id from tb where id = 1; </li></ul></li><li>（索引合并）多个单列索引合并使用<ul><li>select * from tb where id=1 and name=’xixi’; </li></ul></li></ul><p>组合索引效率 &gt; 索引合并</p><h2 id="索引类型"><a href="#索引类型" class="headerlink" title="索引类型"></a>索引类型</h2><p>索引是<strong>在存储引擎层而不是服务层实现的</strong>。不同的存储引擎的索引的工作方式并不相同，也不是所有的存储引擎都支持所有类型的索引。即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。这里只提两个常见的索引类型。</p><h3 id="B-Tree索引"><a href="#B-Tree索引" class="headerlink" title="B-Tree索引"></a>B-Tree索引</h3><ul><li>B-Tree <ul><li>常用</li><li>将索引放置于树中</li><li>有利于范围查找</li></ul></li></ul><p>存储引擎以不同的方式使用B-Tree索引，性能也各有不同，各有优劣。例如，<strong>MyISAM使用前缀压缩技术使得索引更小</strong>，<strong>但InnoDB则按照原数据格式进行存储</strong>。再如MyISAM索引通过<strong>数据的物理位置</strong>引用被索引的行，而InnoDB则<strong>根据主键引用被索引的行。</strong></p><p>B-Tree通常意味着所有的值都是<strong>按顺序存储的</strong>，并且<strong>每个叶子页到根的距离相同</strong>。</p><p>B-Tree索引能够加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要的数据，取而代之的是从索引的根节点开始进行搜索。根节点的槽中<strong>存放了指向子结点的指针</strong>，存储引擎根据这些指针向下层查找。通过比较节点页的值和要查找的值可以找到合适的指针进入下层子结点，这些指针实际上定义了子结点页中值的上限和下限。最终存储引擎要么是找到对应的值，要么该记录不存在。</p><p><strong>叶子节点</strong>比较特别，它们的指针指向的<strong>是被索引的数据</strong>，而不是其他的节点页。<br><img src="https://img-blog.csdn.net/20170412215000060?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvV1NZVzEyNg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="image"></p><p>B-Tree对索引列<strong>是顺序组织存储</strong>的，所以很<strong>适合查找范围数据</strong>。</p><h3 id="hash索引"><a href="#hash索引" class="headerlink" title="hash索引"></a>hash索引</h3><ul><li>hash索引 <ul><li>创建了一个索引哈希表，记录了每个索引的哈希值已经数据存储地址。</li><li>哈希索引表里和原表顺序不同 例如查找id&lt;3的值，则效率慢。但是如果查找id=3，则效率很快。即范围查找慢，单值查找快。</li><li>少用</li></ul></li></ul><p>哈希索引基于哈希表实现。只有<strong>精确匹配</strong>索引所有列的査询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code),哈希码是一个较小的值，并且不同键值的行计算出来的哈希码也不一样。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。</p><p>MySQL中，<strong>只有Memory引擎显式支持哈希索引</strong>。这也是<strong>Memory引擎表的默认索引类型</strong>，Memory引擎同时也支持B-Tree索引。值得一提的是，Memory引擎是支持非唯一哈希索引的，这在数据库世界里面是比较与众不同的。<strong>如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中</strong>。</p><p>因为索引只存储对应的哈希值，所以<strong>索引的结构十分紧凑</strong>，这也让==哈希索引查找的速度非常快==。</p><p>但是哈希索引包含以下缺点：</p><ol><li>哈希索引只包含哈希值和行指针，而<strong>不存储数据值</strong>，所以无法通过索引来避免读取行。（当select只取索引值时）</li><li>哈希表中的哈希值是有序的，但导致<strong>索引值是无序的</strong>，所以<strong>无法用于排序</strong></li><li>哈希索引不支持部分索引列匹配索引。因为<strong>哈希值是根据所有使用的索引列进行计算</strong>。所以当索引为(A,B)时，如果只使用A，索引无效。</li><li>哈希索引<strong>只支持等值查询</strong>。即 = 、 IN()、 &lt;=&gt;。不支持范围查询</li><li>当出现哈希冲突时，需要遍历对应链表的所有行指针，逐行比较。</li><li>如果哈希冲突很多时，一些索引<strong>维护操作的代价也会很高</strong>。例如当做对应的删除操作时，需要遍历对应链表的所有行指针，找到并删除对应行的引用。</li></ol><p>因为这些限制，哈希索引只适用于某些特定的场合。而一旦适合哈希索引，则它带来的性能提升将非常显著。</p><p>Innodb引擎有一个特殊的功能叫“<strong>自适应哈希索引</strong>”。 当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中，基于B-Tree之上再创建一个哈希索引，这样就让B-Tree索引也具有哈希索引的一些优点，比如快速的哈希查找。这是一个完全自动的、内部行为，用户无法控制或配置，但是可以关闭。</p><h4 id="自定义哈希索引-实用"><a href="#自定义哈希索引-实用" class="headerlink" title="自定义哈希索引 **** 实用"></a>自定义哈希索引 **** 实用</h4><p>如果存储引擎不支持哈希索引，可以模拟InnoDB创建哈希索引，这可以享受一些哈希索引的便利，==例如只需要很小的索引就可以为超长的键创建索引==。</p><p>当需要存储大量的URL，并需要根据URL进行搜索查找。如果使用B-Tree来存储URL，存储的内容就会很大，因为URL本身都很长。</p><p>常规查找：</p><pre><code>SELECT id FROM url WHERE url=&quot;http://www.mysql.com&quot;;</code></pre><p>若删除原来URL列上的索引，新增一个被索引的url_crc列，使用CRC32做哈希，就可以使用下面的方式查询：</p><pre><code>SELECT id FROM url WHERE url=&quot;http://www.mysql.com&quot;    AND url_crc=CRC32(&quot;http://www.mysql.com&quot;);</code></pre><p>这样做的性能会非常高，因为MySQL优化器会使用这个选择性很高而体积很小的基于url_crc列的索引来完成查找。只需要根据哈希值做快速的整数比较就能找到索引条目。相比于对完整URL字符串做索引，效率高很多。</p><p>这样实现的缺陷是需要维护哈希值。可以手动通过触发器实现。</p><ol><li>创建表如下：</li></ol><pre><code>CREATE TABLE url_hash_test` (  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,  `url` varchar(255) NOT NULL ,  `url_crc` int(10) unsigned NOT NULL DEFAULT &apos;0&apos;,  PRIMARY KEY (`id)) ENGINE=InnoDB DEFAULT CHARSET=utf8;</code></pre><ol start="2"><li>创建触发器</li></ol><pre><code>DELIMITER //create trigger url_insert before Insert on url_hash_test for each rowbeginset new.url_crc = crc32(new.url);end;//create trigger url_update before update on url_hash_test for each rowbeginset new.url_crc = crc32(new.url);end;//DELIMITER ;</code></pre><p>尽量不要使用SHA1()\MD5()作为哈希函数。因为这两个函数计算出来的哈希值是非常长的字符串，会浪费大量空间，比较时也会更慢。这两个函数都是强加密函数，设计目标是最大限度消除重读，但这里并不需要这样搞的要求。</p><p>一旦出现哈希冲突</p><pre><code>SELECT id FROM url WHERE url_crc=CRC32(&quot;http://www.mysql.com&quot;);</code></pre><p>是无法正确执行的（但是可以用于统计记录数）。所以我们采用哈希值加原数据进行匹配，保证准确性。</p><pre><code>SELECT id FROM url WHERE url=&quot;http://www.mysql.com&quot;    AND url_crc=CRC32(&quot;http://www.mysql.com&quot;);</code></pre><h2 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h2><ul><li>大大减少了服务器需要扫描的数据量</li><li>帮助服务器避免排序和临时表</li><li>索引可以将随机I/O变为顺序I/O</li></ul><h2 id="建立索引的缺点"><a href="#建立索引的缺点" class="headerlink" title="建立索引的缺点"></a>建立索引的缺点</h2><ul><li>额外的文件保存特殊的数据结构</li><li>插入和更新删除效率降低（需要更新索引文件）</li><li>需要命中索引才能发挥作用</li></ul><p>索引并不总是最好的工具。总的来说，<strong>只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时</strong>，索引才是有效的。</p><ul><li>对于非常小的表，大部分情况下简单的全表扫描更高效。</li><li>对于中到大型的表，索引就非常有效</li><li>对于特大型表，建立和使用索引的代价将随之增长。</li></ul><p>对于特大型表的情况下，需要一种技术可以直接区分出查询需要的一组数据，而不是一条一条记录地匹配。例如 <strong>分区技术</strong>。如果表的数据特别多，可以建立一个元数据信息表，用来查询需要用到的某些特性。对于TB级别的数据，定位单条记录的意义不大，所以经常会使用块级别元数据技术来替代索引。</p><h1 id="索引策略"><a href="#索引策略" class="headerlink" title="索引策略"></a>索引策略</h1><p>正确地创建和使用索引是实现高性能查询的基础。</p><h2 id="有效索引"><a href="#有效索引" class="headerlink" title="有效索引"></a>有效索引</h2><p>可以使用B-Tree索引的查询类型。B-Tree索引适用于全键值、键值范围或键前缀查找。其中键前缀查找只适用于根据最左前缀的查找。前面所述的索引对如下类型的查询有效。</p><blockquote><p>前提： key (last_name, first_name, dob)</p><ul><li>全值匹配</li></ul></blockquote><pre><code>全值匹配指的是和索引中的所有列进行匹配，例如前面提到的索引可用于查找姓名为Cuba Allen、出生于1960-01-01的人。</code></pre><ul><li>匹配最左前缀</li></ul><pre><code>前面提到的索引可用于查找所有姓为Allen的人，即只使用索引的第一列。匹配列前缀也可以只匹配某一列的值的开头部分。例如前面提到的索引可用于查找所有以J开头的姓的人。这里也只使用了索引的第一列。</code></pre><ul><li>匹配范围值</li></ul><pre><code>例如前面提到的索引可用于查找姓在Allen和Barrymore之间的人。这里也只使用了索引的第一列。</code></pre><ul><li>精确匹配到某一列并范围匹配另外一列</li></ul><pre><code>前面提到的索引也可用于查找所有姓为Allen，并且名字是字母K开头（比如Kim、Karl等）的人。即第一列last_name全匹配，第二列first_name范围匹配。</code></pre><ul><li>只访问索引的查询</li></ul><pre><code>B-Tree通常可以支持“只访问索引的查询”，即查询只需要访问索引，而无须访问数据行。</code></pre><p>因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY操作（按顺序查找）。<strong>一般来说，如果B-Tree可以按照某种方式查找到值，那么也可以按照这种方式用于排序</strong>。所以，如果ORDER BY子句满足前面列出的几种查询类型，则这个索引也可以满足对应的排序需求。</p><p>下面是一些关于B-Tree索引的限制：</p><ul><li>如果不是按照索引的<strong>最左列</strong>开始查找，则无法使用索引。例如上面例子中的索引在每用于查找名字为Bill的人，也无法查找某个特定生日的人，因为这两列都不是最左数据列。类似地，也无法查找姓氏以某个字母结尾的人。</li><li>不能跳过索引中的列。也就是说，前面所述的索引无法用于查找姓为Smith并且在某个特定日期出生的人。如果不指定名（first_name），则MySQL只能使用索引的第一列。</li><li>如果查询中有某个列的<strong>范围</strong>(like between &gt; &lt; 都算范围查询)查询，<strong>则其右边所有列都无法使用索引优化查找</strong>。例如有查询WHERE lastname=’Smith’AND firstname like ‘%J%’AND dob＝’1976-12-23＇，这个查询只能使用索引的前两列，因为这里的like是一个范围条件（但是服务器可以把其余列用于其他目的）。如果范围查询列值的数量有限，那么可以通过使用多个等于条件来代替范围条件。</li></ul><p>所以前面提到的<strong>索引列的顺序</strong>是多么的重要：这些限制都和索引列的顺序有关。在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足不同类型的查询需求。</p><p>也有些限制并不是B-Tree本身导致的，而是MySQL优化器和存储引擎使用索引的方式导致的，这部分限制在未来的版本中可能就不再是限制了。</p><h2 id="高效使用索引的策略"><a href="#高效使用索引的策略" class="headerlink" title="高效使用索引的策略"></a>高效使用索引的策略</h2><h3 id="独立的列"><a href="#独立的列" class="headerlink" title="独立的列"></a>独立的列</h3><p><strong>索引不能是表达式的一部分，也不能是函数的参数。</strong></p><pre><code>SELECT actor_id FROM actor WHERE actor_id + 1 =5;</code></pre><p>如以上查询，无法使用actor_id列索引。MySQL无法自动解析这个方程，这完全是用户行为。我们应该养成化简WHERE条件的习惯，始终将索引列单独放在比较符号的一侧。</p><h3 id="前缀索引和索引选择性"><a href="#前缀索引和索引选择性" class="headerlink" title="前缀索引和索引选择性"></a>前缀索引和索引选择性</h3><p>有时候索引很长的字符列，这会让索引变得大且慢。通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性（可以理解为准确度，唯一索引的选择性为1）。</p><p>所以我们要再选择性足够高的前提下，减少索引值的长度。</p><pre><code>SELECT COUNT(*)AS cnt, LEFT(city, 3) AS pref    FROM city GROUP BY pref ORDER BY cnt DESC LIMIT 10;</code></pre><p>通过left截取长度，分组排序。然后和原数据进行比较，查看选择性足够高时，合适的字符长度。</p><h3 id="选择合适的索引列顺序（B-Tree）"><a href="#选择合适的索引列顺序（B-Tree）" class="headerlink" title="选择合适的索引列顺序（B-Tree）"></a>选择合适的索引列顺序（B-Tree）</h3><p>由于哈希或者其他类型的索引不会像B-Tree索引一样按顺序存储数据，本节只适合B-Tree索引。</p><p>经验法则：将选择性最高的列放到索引最前列。（在某些场景有效，需要更全面考虑）</p><p><strong>当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的。因为此时索引的作用只是用于优化WHERE条件查找，确实能够最快地过滤出需要的行。</strong></p><p>然而，性能不只依赖于所有索引列的选择性，也和查询条件的具体值有关，<strong>也就是和值的分布有关</strong>。可能需要根据那些运行频率最高的查询来调整索引列的顺序，让这种情况下索引的选择性最高。</p><pre><code>SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,COUNT(*)FROM payment;</code></pre><p>可以通过类似代码，计算出不同列的选择性，然后将选择性大的放于前面。</p><p>当某些特殊值作为查询条件导致性能很差时，也可以查询某个值在该列的占比，当占比很高，代表选择性很低，不适合作为索引条件查询。可以禁止这些特殊值应用于某个查询。</p><h3 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h3><p>聚簇索引并不是一种单独的索引类型，而是==一种数据存储方式==。InnoDB的聚簇索引实际上在<strong>同一个结构中保存了B-Tree索引和数据行</strong>。</p><p>当表有聚簇索引时，它的数据行实际上<strong>存放在索引的叶子页中</strong>。因为无法同时把数据行存放在两个不同的地方，所以==一个表只能由一个聚簇索引==。</p><blockquote><p>索引是由存储引擎实现的，所以并不是所有的存储引擎都支持聚簇索引。此处主要关注InnoDB</p></blockquote><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1564069095908&di=4a1a6dcf5219a17505f186de935e0bed&imgtype=jpg&src=http%3A%2F%2Fimg0.imgtn.bdimg.com%2Fit%2Fu%3D1032547455%2C1945044674%26fm%3D214%26gp%3D0.jpg" alt="image"><br>如图，叶子页包含了行的全部数据，但是节点页只包含了索引列。</p><p><strong>InnoDB将通过主键聚集数据</strong>。（一些数据库服务允许选择哪个索引作为聚簇索引。）</p><pre><code>如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果也没有，则会隐式定义一个主键来作为聚簇索引。InnoDB只聚集在同一个页面中的记录。包含相邻键值的页面可能会相距甚远。</code></pre><h4 id="聚簇索引的优缺点"><a href="#聚簇索引的优缺点" class="headerlink" title="聚簇索引的优缺点"></a>聚簇索引的优缺点</h4><p>优点：</p><ul><li>可以把相关数据保存在一起</li><li>数据访问更快。由于索引和数据保存在一起，因此从聚簇索引中获取数据通常比非聚簇索引中查找要快</li><li>使用覆盖索引扫描的查询可以直接使用页节点中的主键值。</li></ul><p>缺点：</p><ul><li>聚簇数据最大限度地提高了I/O密集型应用的性能，但如果数据都放在内存中，则访问顺序就没那么重要了，聚簇索引就没有什么优势了。</li><li>插入速度严重依赖于插入顺序。（内部是按主键排序的。如果乱序插入后，建议使用OPTIMIZE TABLE命令重新组织一下表）</li><li>更新聚簇索引列的代价很高。会强制InnoDB将每个被更新的行移动到新的位置。</li><li>在插入新行或者主键更新时，可能某个页已满，需要进行页分裂。影响效率，并且占用更多的磁盘空间。</li><li>全表扫描更慢，尤其是行比较稀疏的情况，或者由于页分裂导致<strong>数据存储不连续</strong>。</li><li>二级索引（非聚簇索引）更大，因为需要存储主键列。</li><li>二级索引访问需要两次查找。（在二级索引中，先找到主键值，再去聚簇索引找对应的行）</li></ul><h4 id="InnoDB和MyISAM的数据分布对比"><a href="#InnoDB和MyISAM的数据分布对比" class="headerlink" title="InnoDB和MyISAM的数据分布对比"></a>InnoDB和MyISAM的数据分布对比</h4><p><strong>MyISAM中主键索引和其他所有在结构上没有什么不同</strong>。主键索引就是一个名为PRIMART的唯一非空索引。</p><p>在InnoDB中，<strong>聚簇索引“就是”表</strong>，每一个叶子节点都包含了主键值、事务ID、用于事务和MVCC的回滚指针以及所有的剩余列。而在二级索引（非聚簇索引）中，叶子节点中存储的不是“行指针”，而是主键值，通过主键值在聚簇索引中找到对应行。虽然占用更多空间，但在移动行时无需更新二级索引中的这个“指针”。</p><p><img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=3582158349,4292250563&fm=26&gp=0.jpg" alt="image"></p><h4 id="在InnoDB表中按主键顺序插入行"><a href="#在InnoDB表中按主键顺序插入行" class="headerlink" title="在InnoDB表中按主键顺序插入行"></a>在InnoDB表中按主键顺序插入行</h4><p>==推荐使用自增AUTO_INCREMENT列作为主键==，这样可以保证数据行是按顺序写入，对于根据主键做关联操作的性能也会更好。</p><p><strong>最好避免不连续且值分布范围非常大的聚簇索引</strong>，特别是对于I/O密集型的应用。从性能的角度考虑，使用UUID来作为聚簇索引则会很糟糕：它使得聚簇索引的插入变得完全随机，这是最坏的情况，使得数据没有任何聚集特性。</p><p>如果主键是顺序的，InnoDB只需要把插入是记录放在上一条记录的后面。当达到页的最大填充因子时（InnoDB默认的最大填充因子是页大小的15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这样顺序加载，那么主键页就会近似于被顺序的记录填满（利用率高，而不是一个页只保存稀疏的数据），这页正是所期待的结果。</p><p>如果采用类似uuid的随机主键值，每插入一条数据InnoDB都需要寻找合适的位置并分配空间（频繁地做页分裂操作）。这会增加很多额外工作，并导致数据分布不够优化（页变得稀疏），并且导致最终数据会有碎片。</p><h5 id="顺序的主键什么时候会造成更坏的结果？"><a href="#顺序的主键什么时候会造成更坏的结果？" class="headerlink" title="顺序的主键什么时候会造成更坏的结果？"></a>顺序的主键什么时候会造成更坏的结果？</h5><p>对于<strong>高并发工作负载</strong>，如果按照顺序插入，会造成明显的争用。主键的上界会成为“热点”，因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。另一个热点可能是AUTO_INCREMENT锁机制。如果遇到这个问题，可能需要考虑重新设计表或应用，或者更改innodb_autoinc_lock_mode配置。</p><h3 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h3><p>如果可以使用索引来直接获取列的数据，不需要回表查询，则称为覆盖索引。</p><p>好处：</p><ul><li>索引条目通常小于数据行大小，会极大减少数据访问量。这对缓存的负载非常重要，因为这种情况下响应实际大部分花费在数据拷贝上。对于I/O密集型的应用，因为所有比数据更小，更容易全部放入内存中。</li><li>如果二级主键能够覆盖查询，则可以避免对主键索引的二次查询</li></ul><p><strong>覆盖索引必须要存储索引列的值</strong>，而哈希索引、空间索引等都不存储索引列的值，所以mysql只能使用B-Tree索引做覆盖索引。</p><h3 id="索引扫描来做排序"><a href="#索引扫描来做排序" class="headerlink" title="索引扫描来做排序"></a>索引扫描来做排序</h3><p>mysql由两种方式生成有序的结果</p><ul><li>通过排序</li><li>按索引顺序扫描。</li></ul><p>扫描索引本身是很快的，因为只需要从一条索引记录移动扫紧接着的下一条记录。但<strong>如果索引不能覆盖查询所需的全部列</strong>，那么就不得不扫描一条索引记录就回表查询一次对于的行。这基本上都是随机I/O。因此按索引顺序读取数据的速度通常要比顺序地全表扫描慢，尤其是在I/O密集型的工作负载时。 </p><p>只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向都一样时，mysql才能使用索引来对结果做排序。</p><p>不满足最左前缀也能利用索引排序：即前缀列的条件为常量时</p><pre><code># key(date, id)where date=&apos;2005-05-25&apos; order by id</code></pre><h3 id="压缩（前缀压缩）索引"><a href="#压缩（前缀压缩）索引" class="headerlink" title="压缩（前缀压缩）索引"></a>压缩（前缀压缩）索引</h3><p>MyISAM使用前缀压缩来减少索引的大小，从而让更多的索引可以放入内存中，这在某些情况下能极大地提高性能。默认只压缩字符串，但通过参数也可以对整数做压缩。</p><p>压缩每个索引块的方法是，先完全保存索引块中的第一个值，然后将其他值和第一个值进行比较得到相同前缀的字节数和剩余不同的后缀部分，把这部分存储起来。</p><pre><code>索引块第一个值是“perform”第二个值是 “performance”则第二个值存储的类似 7，ance</code></pre><p>压缩块使用更少的空间，代价是某些操作可能更慢。因为每个值的压缩前缀都依赖于前面的值，导致的缺点是：</p><ul><li>无法在索引块使用二分查找</li><li>正序扫描速度还行，倒叙很差</li><li>随即查找速度差</li></ul><h3 id="冗余和重复、未使用索引"><a href="#冗余和重复、未使用索引" class="headerlink" title="冗余和重复、未使用索引"></a>冗余和重复、未使用索引</h3><p>重复、未使用的索引无疑要删除。（例如对主键列又设置了唯一索引）</p><p>冗余索引则需要分情况讨论。</p><p>如果创建索引(A, B)再创建索引(A)就冗余了，因为这只是前一个索引的前缀索引（只对B-Tree索引来说）。但如果创建(B, A)、(B)则不是冗余索引，因为它们都不是(A, B)的最左前缀列。</p><p>冗余索引通常发生在为表添加新索引的时候。例如在已有索引(A)，不考虑扩展成(A, B)而直接添加新索引(A, B)</p><p>大多数时候都不需要冗余索引，==应该尽量扩展已有的索引而不是创建新的索引==。</p><p>但是如果额外需要添加索引是类似一个很长的VARCHAR列，如果采用扩展的策略，对于前一个索引来说性能可能会急剧下降。特别是有查询把这个索引当作覆盖索引，或者是MyISAM表并且有很多防卫查询的时候。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>单行访问是很慢的。如果从存储中读取一个数据块只是为了获取其中一行，则浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引用以提高效率</li><li>按顺序访问访问数据是很快的。两个原因：顺序I/O不需要多次磁盘寻道，比随机I/O快很多。二，如果能按需要顺序取数据，则不需要额外的排序操作</li><li>索引覆盖查询很快。</li></ul><h2 id="命中索引"><a href="#命中索引" class="headerlink" title="命中索引"></a>命中索引</h2><ol><li>like<ul><li>模糊查询以%开头，会导致索引失效</li><li>即使不以%开头，使用like也会降低查询效率</li><li>如果用户量很大的话，不使用like 而会导入第三方工具处理文字</li></ul></li><li>避免使用函数<ul><li>例如使用reverse(email) 会导致索引失效</li><li>尽量将类似的功能在代码中完成</li></ul></li><li>or<ul><li>当or条件中有未建立的索引列会失效</li><li>例： SELECT * FROM TB WHERE 索引列 or 非索引列 则在此 索引失效</li><li>但是 SELECT * FROM TB WHERE 索引列 or 非索引列 and 索引列 则会只用首尾的索引列</li></ul></li><li>类型不一致<ul><li>即传入的数据类型要与列类型相符 不然索引失效</li><li>例如列类型为字符 而传入数</li></ul></li><li>！= &gt;<ul><li>普通索引使用 ！= 索引失效 但主键有效</li><li>普通索引字符型 &gt; 索引失效 数字或者主键有效</li></ul></li><li>order by<ul><li>当根据索引排序时，选择的映射如果不是索引，则失效</li><li>例如： select name from tb where email=’123@’ email是索引，但映射name 索引失效</li><li>但是对主键排序，索引有效</li></ul></li><li>最左前缀<ul><li>如果组合索引为（name，email）</li><li>name and email 有效</li><li>name  有效</li><li>email 失效</li></ul></li><li>一个表建的索引尽量不要超过5个。</li><li>尽量使用覆盖索引。</li><li>尽量不要在重复数据多的列上建索引。</li><li>…</li></ol><h1 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h1><p>在Inodb存储引擎中，也有页的概念，默认每个页的大小为16K，也就是每次读取数据时都是读取4 * 4K的大小。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nAurWR1GqU0EAJdyjPG3icld7mTPRcCJ5rjoPXjahZbZLJicwf73JmtBaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>在某个页内插入新行时，为了减少数据的移动，通常是插入到<strong>当前行的后面或者是已删除行留下来的空间</strong>，所以在某一个页内的数据<strong>并不是完全有序的</strong>，但是为了数据访问顺序性，在每个记录中<strong>都有一个指向下一条记录的指针</strong>，以此构成了一条单向有序链表，不过在这里为了方便演示我是按顺序排列的！</p><p>由于数据还比较少，一个页就能容下，所以只有一个根结点，主键和数据也都是保存在根结点（左边的数字代表主键，右边名字、性别代表具体的数据）。假设我们写入10条数据之后，Page1满了，再写入新的数据会怎么存放呢？<br><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nAl8Lu51lULrqktDiboj9uhL7I1vrgIZLfEGWeP3A6c2S3xw81hRjDVLw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>这时候需要进行页分裂，产生一个新的Page。在innodb中的流程是：</p><ol><li>产生新的Page2，然后将Page1的内容复制到Page2</li><li>产生新的Page3，将新插入的数据（“秦寿生”）放入Page3</li><li>原来的Page1依然作为根结点，但是变成了一个不存放数据只存索引的页，并且有两个子结点Page2、Page3</li></ol><p>这里有两个问题：</p><ol><li>为什么要复制Page1为Page2而不是创建一个新的页作为根结点，这样就<strong>少了一步复制的开销</strong>了？</li></ol><p>如果是重新创建根结点，那==根结点存储的物理地址可能经常会变==，不利于查找。并且==在innodb中根结点是会预读到内存中的，所以结点的物理地址固定会比较好==！</p><ol start="2"><li>原来Page1有10条数据，在插入第11条数据的时候进行裂变，根据前面对B-Tree、B+Tree特性的了解，那这至少是一颗11阶的树，裂变之后每个结点的元素至少为11/2=5个，那是不是应该页裂变之后主键1-5的数据还是在原来的页，<strong>主键6-11的数据会放到新的页</strong>，根结点存放主键6？</li></ol><p>如果是这样的话新的页==空间利用率只有50%==，并且会==导致更为频繁的页分裂==。所以innodb对这一点做了<strong>优化</strong>，<strong>新的数据放入新创建的页，不移动原有页面的任何记录</strong>。</p><p>每次新增数据，都是将一个页写满，然后新创建一个页继续写，这里其实是有个隐含条件的，那就是==主键自增==！主键自增写入时新插入的数据不会影响到原有页，插入效率高！且页的利用率高！但是如果主键是无序的或者随机的，那每次的插入可能会导致原有页频繁的分裂，影响插入效率！降低页的利用率！<strong>这也是为什么在innodb中建议设置主键自增的原因</strong>！</p><p>这棵树的非叶子结点上存的都是主键，那如果一个表<strong>没有主键会怎么样</strong>？在innodb中，如果一个表没有主键，那默认会找<strong>建了唯一索引的列</strong>，如果也没有，则会<strong>生成一个隐形的字段作为主键</strong>！</p><p>有数据插入那就有删除，如果这个用户表频繁的插入和删除，那会导致<strong>数据页产生碎片</strong>，<strong>页的空间利用率低，还会导致树变的“虚高”，降低查询效率</strong>！这可以通过==索引重建==来消除碎片提高查询效率！</p><h2 id="innodb引擎数据查找"><a href="#innodb引擎数据查找" class="headerlink" title="innodb引擎数据查找"></a>innodb引擎数据查找</h2><ol><li>找到数据所在页。这个查找过程和B+树的搜索过程意义，从根结点开始查找一直到叶子结点。</li><li>在页内找具体的数据。读取第一步找到的叶子结点数据到内存中，然后通过<strong>分块查找</strong>的方法找到具体的数据。</li></ol><p>这跟我们在新华字典中找某个汉字是一样的，先通过字典的索引定位到该汉字拼音所在的页，然后到指定的页找到具体的汉字。innodb中定位到页后用了哪种策略快速查找某个主键呢？这我们就需要从页结构开始了解。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nACeTfTyfM4xMLBXPsauj0FX693VujKqeg6JibLp2G1cMtJxEwPVt8o2g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><ul><li>左边蓝色区域称为Page Directory，这块区域由多个slot组成，是一个<strong>稀疏索引结构</strong>，即一个槽中可能属于多个记录，最少属于4条记录，最多属于8条记录。槽内的数据是有序存放的，所以当我们寻找一条数据的时候可以先在槽中通过二分法查找到一个大致的位置。</li><li>右边区域为数据区域，每一个数据页中都包含多条行数据。注意看图中最上面和最下面的两条特殊的行记录Infimum和Supremum，这是两个虚拟的行记录。<strong>在没有其他用户数据的时候Infimum的下一条记录的指针指向Supremum，当有用户数据的时候，Infimum的下一条记录的指针指向当前页中最小的用户记录，当前页中最大的用户记录的下一条记录的指针指向Supremum，至此整个页内的所有行记录形成一个单向链表</strong>。</li><li>行记录被Page Directory逻辑的分成了多个块，<strong>块与块之间是有序的</strong>，也就是说“4”这个槽指向的数据块内最大的行记录的主键都要比“8”这个槽指向的数据块内最小的行记录的主键要小。<strong>但是块内部的行记录不一定有序</strong>。</li><li>每个行记录的都有一个nowned的区域（图中粉红色区域），<strong>nowned标识这个这个块有多少条数据</strong>，伪记录Infimum的nowned值总是1，记录Supremum的nowned的取值范围为[1,8]，其他用户记录nowned的取值范围[4,8]，并且只有<strong>每个块中最大的那条记录的nowned才会有值，其他的用户记录的n_owned为0</strong>。</li><li>所以当我们要找主键为6的记录时，先通过二分法在稀疏索引中找到对应的槽，也就是Page Directory中“8”这个槽，“8”这个槽指向的是该数据块中最大的记录，而数据是<strong>单向链表结构所以无法逆向查找，所以需要找到上一个槽即“4”这个槽</strong>，然后通过“4”这个槽中最大的用户记录的指针沿着链表顺序查找到目标记录。</li></ul><h2 id="聚集索引-amp-非聚集索引"><a href="#聚集索引-amp-非聚集索引" class="headerlink" title="聚集索引 &amp; 非聚集索引"></a>聚集索引 &amp; 非聚集索引</h2><ul><li>聚集索引：数据与索引存放在一起，找到索引就找到了数据。</li><li>非聚集索引：将数据和索引分开存储，索引结构的叶子节点指向数据的对于行</li></ul><p>InnoDB中，在聚簇索引之上创建的索引称之为辅助索引。辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，例如：复合索引、前缀索引、唯一索引，辅助索引叶子结点存储的<strong>不再是行的物理地址，而是主键值</strong>。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。</p><p>==聚簇索引具有唯一性==。由于将数据和索引结构存放在一起，因此一个表仅有一个聚簇索引。</p><p>==聚簇索引默认是主键==，如果表中没有主键，InnoDB会选择一个<strong>唯一的非空索引代替</strong>。如果也没有，InnoDB会隐式的定义一个主键来作为聚簇索引。</p><p>聚簇索引性能最好而且具有唯一性，所以非常珍贵，必须慎重设置。一般要根据这个表最常用的SQL查询方式来进行选择，某个字段作为聚簇索引，或组合聚簇索引，这个要看实际情况。</p><p><strong>我们最终目的就是在相同结果集情况下，尽可能减少逻辑IO。</strong></p><p><img src="https://upload-images.jianshu.io/upload_images/10154499-5244179cc19a1c21.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/164/format/webp" alt="image"><br><img src="https://upload-images.jianshu.io/upload_images/10154499-5772dddedb909374.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/633/format/webp" alt="image"></p><ol><li><strong>InnoDB使用的是聚簇索引</strong>，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用”where id = 14”这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。</li><li>若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）<strong>拿聚集索引的key到主键索引树上查找对应的数据</strong>，这个过程称为<strong>回表</strong>！</li><li>MyISM使用的是非聚簇索引，非聚簇索引的两棵B+树看上去没什么不同，<strong>节点的结构完全一致只是存储的内容不同而已</strong>，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。表数据存储在独立的地方，<strong>这两颗B+树的叶子节点都使用一个地址指向真正的表数据</strong>，对于表数据来说，这两个键没有任何差别。由于索引树是独立的，通过辅助键检索无需访问主键的索引树。</li></ol><h3 id="聚簇索引的优势、劣势"><a href="#聚簇索引的优势、劣势" class="headerlink" title="聚簇索引的优势、劣势"></a>聚簇索引的优势、劣势</h3><p>看上去聚簇索引的效率明显要低于非聚簇索引，因为每次使用辅助索引检索都要经过两次B+树查找，这不是多此一举吗？聚簇索引的优势在哪？</p><ol><li>由于<strong>行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问</strong>，不必访问磁盘。这样<strong>主键和行数据是一起被载入内存的</strong>，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。</li><li>辅助索引使用主键作为”指针”而不是使用地址值作为指针的好处是，<strong>减少了当出现行移动或者数据页分裂时辅助索引的维护工作</strong>，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个”指针”。也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），<strong>使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响</strong>。</li><li>聚簇索引适合用在排序的场合，非聚簇索引不适合</li><li>取出一定范围数据的时候，使用用聚簇索引</li><li>二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据</li><li>可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。</li></ol><p>存在的劣势：</p><ol><li><strong>维护索引很昂贵</strong>，特别是插入新行或者主键被更新导至要分页(page split)的时候。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片</li><li>表因为使用UUId（随机ID）作为主键，使<strong>数据存储稀疏</strong>，这就会出现聚簇索引有可能有比全表扫面更慢，所有建议使用主键自增。<br><img src="https://upload-images.jianshu.io/upload_images/10154499-ee09c38aeb148cd0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/728/format/webp" alt="image"><br><img src="https://upload-images.jianshu.io/upload_images/10154499-75ad3e0e24d55317.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/730/format/webp" alt="image"><br>主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）</li><li>如果主键比较大的话，那辅助索引将会变的更大，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间</li></ol><h2 id="为什么都建议使用自增主键？"><a href="#为什么都建议使用自增主键？" class="headerlink" title="为什么都建议使用自增主键？"></a>为什么都建议使用自增主键？</h2><p>==因为使用自增主键可以避免页分裂。==</p><p>在InnoDB中，底层的数据结构是B+树。<strong>所谓的索引其实就是一颗B+树，一个表有多少个索引就会有多少棵B+树，mysql中的数据都是按顺序保存在B+树上的（所以说索引本身是有序的。）</strong></p><p>mysql在底层又是以数据页为单位来存储数据的，一个数据页大小默认为16K，当然也可以自定义大小。如果一个数据页存满了，mysql就会去申请一个新的数据页来存储数据。</p><p>如果主键为自增id的划，mysql在写满一个数据页的时候，直接申请另一个数据页接着写就可以了。聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增id，那么可以想 象，它会干些什么，<strong>为了确保索引有序，mysql就需要将每次插入的数据都放到合适的位置上</strong>。不断地调整数据的物理地址、分页（需要把上个数据页的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的。），当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。</p><p>另外在满足业务需求的情况下，<strong>尽量使用占空间更小的主键id</strong>，因为普通索引的叶子结点上保存的是主键id的值，如果主键id占空间较大的划，会成倍增加mysql空间占用大小。</p><p>因为MyISAM的主索引并非聚簇索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转。聚簇索引则只需一次I/O。（强烈的对比）<br>不过，如果涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的。</p><h2 id="innodb与MyISAM对比"><a href="#innodb与MyISAM对比" class="headerlink" title="innodb与MyISAM对比"></a>innodb与MyISAM对比</h2><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nAz97l1Fkf0JHsBUBUMlWeByLwCHXibr0PErC5QFBc8LrUTZQBsiaYAscw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"><br>MyISAM主键索引的存储结构与innodb不同的是：</p><ol><li>主键索引树的叶子结点的数据区域没有存放实际的数据，存放的是数据记录的地址</li><li>数据的存储不是按主键顺序存放的，按写入的顺序存放的</li></ol><p>也就是说innodb引擎数据<strong>在物理上是按主键顺序存放</strong>，而MyISAM引擎数据<strong>在物理上按插入的顺序存放</strong>。并且MyISAM的叶子结点不存放数据，所以与 非聚集索引的存储结构与聚集索引类似，在使用非聚集索引查找数据的时候通过非聚集索引树就能直接找到数据的地址了，<strong>不需要回表</strong>，这比innodb的搜索效率会更高呢！</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3NDA4OTk1OQ==&mid=2649902711&idx=2&sn=321495d655706908f3dae55dbca5ac67&chksm=f31fbcffc46835e99df2f7918cea451f3773ee86bad7532d34c0802153952321ebbee3445eb2&scene=0&xtrack=1&key=2e81df8e5d9650c8f3ac53b0be90f792fd0d69e6d6c4c46e5a7ff73a646e4efdedb59b7814e5313bfc3925c9e6f104a840fb24b23844d987c51925c9bc373d43097c19834ee86da8472166e1ac0cad6f&ascene=1&uin=Nzc2Njg1NjA%3D&devicetype=Windows+10&version=62060833&lang=zh_CN&pass_ticket=zM8YhCidUZRbx7tcac%2BS4I%2ByO0dRflFTUyAQ31tuk%2BY%3D" target="_blank" rel="noopener">引用自推文1</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI3NDA4OTk1OQ==&mid=2649902693&idx=1&sn=f3c6feca92d6dcbf459ceb88c00f15e2&chksm=f31fbcedc46835fb12f107ec6374894abc173cfbd86b315a1fe31ab2c465ffd5815818d630f5&scene=0&xtrack=1&key=f6d26f92f2a2f56dc9b6f9b55bbe738b19362226ac7fa3db04754567598280e28b6c159303b828892096479839391e3164899e4ced7d02712ad0d864a908fdab6accc8cada7904235092ab7c66bc2267&ascene=1&uin=Nzc2Njg1NjA%3D&devicetype=Windows+10&version=62060833&lang=zh_CN&pass_ticket=r4UXL%2BID8d22QttiIC9nlF%2FMakFkL0RClc0NsQF4vpE%3D" target="_blank" rel="noopener">引用自推文2</a></p><p><a href="https://www.jianshu.com/p/fa8192853184" target="_blank" rel="noopener">文章</a></p><blockquote><p>《高性能mysql》</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;索引基础&quot;&gt;&lt;a href=&quot;#索引基础&quot; class=&quot;headerlink&quot; title=&quot;索引基础&quot;&gt;&lt;/a&gt;索引基础&lt;/h1&gt;&lt;p&gt;索引的作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;加速查找&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;约束
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://sssmeb.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>B、B+树的理解（数据库索引预热）</title>
    <link href="https://sssmeb.github.io/2019/08/01/B%E3%80%81B-%E6%A0%91%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%88%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E9%A2%84%E7%83%AD%EF%BC%89/"/>
    <id>https://sssmeb.github.io/2019/08/01/B、B-树的理解（数据库索引预热）/</id>
    <published>2019-08-01T11:21:59.000Z</published>
    <updated>2019-08-15T08:54:35.021Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要有B树"><a href="#为什么要有B树" class="headerlink" title="为什么要有B树"></a>为什么要有B树</h1><ol><li>局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。</li><li>同样的数据，红黑树（二叉树）阶数更大，B树更短，查找的效率越高。</li></ol><h1 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h1><p><strong>B树大量应用在数据库和文件系统中。</strong></p><p>B树建立在二叉树和平衡二叉树的基础上。在二叉树中，每个结点只有一个元素。但是在B-Tree中，每个结点都可能包含多个元素，并且非叶子结点在元素的左右都有指向子结点的指针。</p><p>他的设计思想是，==将相关数据尽量集中在一起，以便一次读取多个数据，减少磁盘操作次数==。B树为系统<strong>最优化大块数据的读和写操作</strong>。B树算法减少定位记录时所经历的中间过程，从而加快存取速度。</p><p>B-Tree的特性有：</p><ol><li>每个结点最多m个子结点</li><li>除根、叶结点，每个结点最少有m/2（向上取整）个子结点</li><li>如果根不是叶子结点，那根结点至少包含两个子结点</li><li>所有叶子结点都位于同一层</li><li>每个结点都包含k个元素（关键字），这里m/2 &lt;= k &lt; m （向下取整）</li><li>每个元素（关键字）左结点的值，都小于等于该元素（关键字）。右结点的值都大于等于该元素（关键字）</li></ol><p>B-Tree的查询效率总是等价于二分查找，并不比平衡二叉树高。但是查询所经过的<strong>结点数量要少很多</strong>，也就意味着要==少很多次的磁盘IO==，这对性能的提升是很大的。</p><p><img src="https://www.e-learn.cn/sites/default/files/ueditor/1/upload/image/20180623/1529717889218072.png" alt="image"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nAN8jfQcWibZCds11libInWNrcM9cX4IZJ3kWGbV06T1RQCF8vJY16j66A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><p>普通的B-Tree的结点中，元素就是一个个的数字。但是上图中，我们把元素部分拆分成了key-data的形式，key就是数据的主键，data就是具体的数据。这样我们在找一条数的时候，就沿着根结点往下找就ok了，效率是比较高的。</p><p>B树是二叉树的改进。</p><p>假定一个节点可以容纳100个值，那么3层的B树可以容纳100万个数据，如果换成二叉查找树，则需要20层！假定操作系统一次读取一个节点，并且根节点保留在内存中，那么B树在100万个数据中查找目标值，只需要读取两次硬盘。B 树可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。</p><h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h1><p>B+Tree是在B-Tree基础上的一种优化，使其更适合实现外存储索引结构。B+Tree与B-Tree的结构很像，但是也有几个自己的特性：</p><ol><li>非叶子节点的子树指针与key个数相同</li><li>非叶子节点的子树指针P[i] 指向key值属于<code>[K[i],K[i+1]]</code>(B树是开区间)</li><li>所有的非叶子结点只存储关键字信息</li><li>所有具体数据都存在叶子结点中</li><li>所有叶子结点中包含了全部元素的信息</li><li>所有叶子节点<strong>之间</strong>都有一个链指针</li></ol><p><img src="https://www.e-learn.cn/sites/default/files/ueditor/1/upload/image/20180623/1529717890596849.png" alt="image"><br>即转化为<br><img src="https://mmbiz.qpic.cn/mmbiz_png/QCu849YTaIMia2uJOKibs2zcvB0ibuicq1nALZNHCiarYworb38ibPFhrarTorlXRERU9lvo8KkyrVXz2xNgN1q65XoQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="image"></p><h1 id="B树和B-树"><a href="#B树和B-树" class="headerlink" title="B树和B+树"></a>B树和B+树</h1><p>首先，我们要知道，操作系统从磁盘读取数据到内存是==以磁盘块为基本单位==，<strong>位于同一个磁盘块的数据会被一次性读取除来</strong>，而不是需要什么取什么。即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。</p><blockquote><p>理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。</p></blockquote><p>预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k）。</p><p>B-Tree和B+Tree该如何选择呢？都有哪些优劣呢？</p><ol><li>B-Tree因为非叶子结点也保存具体数据，所以在查找某个关键字的时候<strong>找到即可返回</strong>。而B+Tree所有的数据都在叶子结点，每次查找都得到叶子结点。<strong>所以在同样高度的B-Tree和B+Tree中，B-Tree查找某个关键字的效率更高</strong></li><li>由于B+Tree所有的数据都在叶子结点，并且结点之间有指针连接，在找<strong>大于某个关键字或者小于某个关键字的数据的时候，B+Tree只需要找到该关键字然后沿着链表遍历就可以了</strong>，而B-Tree还需要遍历该关键字结点的根结点去搜索。</li><li>由于B-Tree的每个结点（这里的结点可以理解为一个数据页）都存储主键+实际数据，而B+Tree非叶子结点只存储关键字信息，而每个页的大小有限是有限的，所以同一页能存储的B-Tree的数据会比B+Tree存储的更少。这样<strong>同样总量的数据，B-Tree的深度会更大，增大查询时的磁盘I/O次数，进而影响查询效率。</strong></li><li>B+树的非叶子节点不包含数据信息，所有内存页中能存放更多的key。<strong>数据存放得更加紧密，具有更好的空间局部性</strong>。因此访问叶子上关联的数据页具有更好的缓存命中率。</li></ol><p>MySQL中InnoDB就是采用B+树的结构。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://www.e-learn.cn/content/qita/809639</span><br><span class="line">https://www.cnblogs.com/nullzx/p/8729425.html</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;为什么要有B树&quot;&gt;&lt;a href=&quot;#为什么要有B树&quot; class=&quot;headerlink&quot; title=&quot;为什么要有B树&quot;&gt;&lt;/a&gt;为什么要有B树&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。&lt;/li&gt;
&lt;li&gt;同样
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://sssmeb.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>用Python实现PING</title>
    <link href="https://sssmeb.github.io/2019/06/24/%E7%94%A8Python%E5%AE%9E%E7%8E%B0PING/"/>
    <id>https://sssmeb.github.io/2019/06/24/用Python实现PING/</id>
    <published>2019-06-24T12:51:03.000Z</published>
    <updated>2019-08-15T08:56:38.148Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PING"><a href="#PING" class="headerlink" title="PING"></a>PING</h1><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>ping属于一个通信协议，是TCP/IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地分析和判定网络故障。</p><p>PING ，用于测试网络连接量的程序。Ping发送一个ICMP（Internet Control Messages Protocol）即因特网信报控制协议；回声请求消息给目的地并报告是否收到所希望的ICMPecho （ICMP回声应答）。它是用来检查网络是否通畅或者网络连接速度的命令。</p><p>它所利用的原理是这样的：利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，再要求对方返回一个同样大小的数据包来确定两台网络机器是否连接相通，时延是多少。</p><p>ping指的是端对端连通，通常用来作为可用性的检查，但是某些病毒木马会强行大量远程执行ping命令抢占你的网络资源，导致系统变慢，网速变慢。严禁ping入侵作为大多数防火墙的一个基本功能提供给用户进行选择。通常的情况下你如果不用作服务器或者进行网络测试，可以放心的选中它，保护你的电脑。</p><h3 id="简单流程"><a href="#简单流程" class="headerlink" title="简单流程"></a>简单流程</h3><ol><li>执行 ping 192.168.0.5</li></ol><pre><code>Ping命令会构建一个固定格式的ICMP请求数据包，然后由ICMP协议将这个数据包连同地址“192.168.0.5”一起交给IP层协议</code></pre><ol start="2"><li>本机IP层相关操作</li><li>本机IP层相关操作</li></ol><pre><code>IP层协议将以地址“192.168.0.5”作为目的地址，本机IP地址作为源地址，加上一些其他的控制信息，构建一个IP数据包发往192.168.0.5。</code></pre><ol start="3"><li>目的主机相关操作</li></ol><pre><code>接收后检查该数据帧，将IP数据包从帧中提取出来，交给本机的IP层协议。IP层检查后，将有用的信息提取后交给ICMP协议ICMP协议后者处理后，马上构建一个ICMP应答包，发送给主机A</code></pre><hr><h3 id="ICMP"><a href="#ICMP" class="headerlink" title="ICMP"></a>ICMP</h3><h4 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h4><p>pin是属于osi七层模型中的应用层。</p><p>ping命令使用的tcp报文还是udp报文呢？</p><p>ping命令使用的是ICMP报文，ICMP报文封装在ip包里。ICMP协议也是tcp/ip协议族中的一个子协议，所以从这一层面来看，icmp报文和tcp报文，udp报文是同一个级别。</p><p>所以ping命令使用的报文既不是tcp报文也不是udp报文。</p><p>但是ICMP 跟TCP和UDP没有归属关系，ICMP位于传输层之下，属网络层。用的IP报头。</p><ul><li><p>TCP/UDP 在第四层：传输层</p></li><li><p>IP/ICMP 在第三层：网络层</p></li></ul><p><img src="https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=3857278002,4035339109&fm=15&gp=0.jpg" alt="image"></p><h6 id="补充IGMP"><a href="#补充IGMP" class="headerlink" title="补充IGMP"></a>补充IGMP</h6><p>IGMP即Internet工作组管理协议（Internet Group Management Protocol）,IGMP主要用来解决网络上广播时占用带宽的问题。</p><p>当网络上的信息要传输给所有工作站时，就发出广播（broadcast）信息（即IP地址主机标识位全为1），交换机会将广播信息不经过滤地发给所有工作站；</p><p>但当这些信息只需传输给某一部分工作站时，通常采用组播（multicast，也称多点广播）的方式，这就要求交换机支持IGMP。支持IGMP的交换机会识别组播信息并将其转发至相应的组，从而使不需要这些信息的工作站的网络带宽不被浪费。IGMP对于提高多媒体传输时的网络性能尤为重要。</p><h4 id="报文结构"><a href="#报文结构" class="headerlink" title="报文结构"></a>报文结构</h4><p><img src="https://img-blog.csdn.net/20180531094213365?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poajA4Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p><h4 id="一、ICMP报文类型"><a href="#一、ICMP报文类型" class="headerlink" title="一、ICMP报文类型"></a>一、ICMP报文类型</h4><table><thead><tr><th>种类</th><th>类型值</th><th>ICMP报文的类型</th></tr></thead><tbody><tr><td>差错报告</td><td>3</td><td>终点不可达</td></tr><tr><td>差错报告</td><td>11</td><td>时间超过</td></tr><tr><td>差错报告</td><td>12</td><td>参数问题</td></tr><tr><td>差错报告</td><td>5</td><td>改变路由</td></tr><tr><td>询问报告</td><td>8/0</td><td>回送请求/回答</td></tr><tr><td>询问报告</td><td>13/14</td><td>时间戳请求/回答</td></tr></tbody></table><h4 id="二、-Checksum-检验和"><a href="#二、-Checksum-检验和" class="headerlink" title="二、 Checksum 检验和"></a>二、 Checksum 检验和</h4><p>校验和基本上是一个从数据包计算出来的值来检查其完整性。通过完整性，我们可以检查收到的数据是否没有错误。</p><p>这是因为在网络上传输时，数据包可能会损坏，并且接收端必须知道数据是否已损坏。这是校验和字段添加到报文的原因。在源端，计算校验和并将其作为字段设置在报文中。在目标端，再次计算校验和，并用报文中现有的校验和值进行交叉检查，看看数据包是否正常。</p><h5 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h5><p>IP检验和，其计算与icmp差不多，但与ip计算不同的是，icmp需要通过其报文信息与本身数据一起校验（IP只需校验头部信息）【因为通常在IP报头之后的数据（如ICMP，TCP等）具有自己的校验和。】。</p><p>因此，就算法而言，imcp校验和是：imcp报文中所有16位字的补码总和的16位补码。</p><ol><li>将校验和字段置为0。</li><li>将每两个字节（16位）相加（二进制求和）直到最后得出结果，若出现最后还剩一个字节继续与前面结果相加。</li><li>(溢出)将高16位与低16位相加，直到高16位为0为止。</li><li>将最后的结果（二进制）取反。</li></ol><p>关于二进制求和：</p><pre><code># 例:# 1. 不溢出时4500  - &gt; 0100010100000000003c  - &gt; 0000000000111100453C  - &gt; 0100010100111100  # 结果# 2. 溢出时 高16位与低16位相加E188  - &gt; 1110000110001000 AC10  - &gt; 101011000001000018D98  - &gt; 110001101100110008D99  - &gt; 1000110110011001   # 结果</code></pre><p>​<br>​    # 最后结果取反<br>​    0A0C  - &gt; 0000101000001100  # 最后一次累加<br>​    4E19  - &gt; 0100111000011001  # 取反得最终结果</p><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><h5 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h5><pre><code># 检验和def chesksum(data):    n = len(data)    m = n % 2    sum = 0    for i in range(0, n - m, 2):        # 传入data以每两个字节（十六进制）通过ord转十进制，第一字节在低位，第二个字节在高位        # ？？？？？为什么第二个字节在高位        sum += (data[i]) + ((data[i+1]) &lt;&lt; 8)        sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff)    if m:        sum += (data[-1])        sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff)    # 取反    answer = ~sum &amp; 0xffff    #  主机字节序转网络字节序列    answer = answer &gt;&gt; 8 | (answer &lt;&lt; 8 &amp; 0xff00)    return answer</code></pre><h6 id="小-大端序"><a href="#小-大端序" class="headerlink" title="小/大端序"></a>小/大端序</h6><p>不同CPU中，4字节整数1在内存空间的存储方式是不同的。若不考虑这些就收发数据会发生问题，因为保存顺序的不同意味着对接收数据的解析顺序也不同。</p><ul><li>大端序（Big Endian）：高位字节存放到低位地址（高位字节在前）。</li><li>小端序（Little Endian）：高位字节存放到高位地址（低位字节在前）。</li></ul><pre><code>保存4字节 int 型数据 0x12345678</code></pre><p>大端序</p><p><img src="http://c.biancheng.net/cpp/uploads/allimg/151109/1-15110ZSA3309.jpg" alt="image"></p><p>小端序</p><p><img src="http://c.biancheng.net/cpp/uploads/allimg/151109/1-15110ZT059560.jpg" alt="image"></p><p>不同CPU保存和解析数据的方式不同（主流的Intel系列CPU为小端序），小端序系统和大端序系统通信时会发生数据解析错误。因此在发送数据前，要将数据转换为统一的格式——网络字节序（Network Byte Order）。网络字节序统一为大端序。</p><h4 id="ICMP实现"><a href="#ICMP实现" class="headerlink" title="ICMP实现"></a>ICMP实现</h4><pre><code># encoding:utf-8import timeimport structimport socketimport select# 检验和def chesksum(data):    n = len(data)    m = n % 2    sum = 0    for i in range(0, n - m, 2):        # 传入data以每两个字节（十六进制）通过ord转十进制，第一字节在低位，第二个字节在高位        sum += (data[i]) + ((data[i+1]) &lt;&lt; 8)        sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff)    if m:        sum += (data[-1])        sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff)    # 取反    answer = ~sum &amp; 0xffff    #  主机字节序转网络字节序列    answer = answer &gt;&gt; 8 | (answer &lt;&lt; 8 &amp; 0xff00)    return answer    def request_ping(data_type, data_code, data_checksum, data_ID, data_Sequence, payload_body):        #  把字节打包成二进制数据        imcp_packet = struct.pack(&apos;&gt;BBHHH32s&apos;, data_type, data_code, data_checksum, data_ID, data_Sequence, payload_body)        # 获取校验和        icmp_chesksum = chesksum(imcp_packet)        #  把校验和传入，再次打包        imcp_packet = struct.pack(&apos;&gt;BBHHH32s&apos;, data_type, data_code, icmp_chesksum, data_ID, data_Sequence, payload_body)        return imcp_packet    # 初始化套接字，并发送    def raw_socket(dst_addr,imcp_packet):        # 实例化一个socket对象，ipv4，原套接字(普通套接字无法处理ICMP等报文)，分配协议端口        rawsocket = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.getprotobyname(&quot;icmp&quot;))        # 记录当前请求时间        send_request_ping_time = time.time()        # 发送数据到网络        rawsocket.sendto(imcp_packet, (dst_addr, 80))        return send_request_ping_time, rawsocket</code></pre><p>​<br>        def reply_ping(send_request_ping_time, rawsocket, data_Sequence, timeout=2):<br>            while True:<br>                ‘’’<br>                select函数，直到inputs中的套接字被触发（在此例中，套接字接收到客户端发来的握手信号，从而变得可读，满足select函数的“可读”条件），<br>                返回被触发的套接字（服务器套接字）；<br>                ‘’’<br>                # 实例化select对象（非阻塞），可读，可写为空，异常为空，超时时间<br>                what_ready = select.select([rawsocket], [], [], timeout)<br>                # 等待时间<br>                # wait_for_time = (time.time() - started_select)<br>                wait_for_time = (time.time() - send_request_ping_time)<br>                # 没有返回可读的内容，判断超时<br>                if what_ready[0] == []:  # Timeout<br>                    return -1<br>                # 记录接收时间<br>                time_received = time.time()<br>                # 设置接收的包的字节为1024<br>                received_packet, addr = rawsocket.recvfrom(1024)<br>                # 获取接收包的icmp头<br>                # print(icmpHeader)<br>                icmpHeader = received_packet[20:28]<br>                # 反转编码<br>                type, code, r_checksum, packet_id, sequence = struct.unpack(<br>                    “&gt;BBHHH”, icmpHeader<br>                )<br><br>                if type == 0 and sequence == data_Sequence:<br>                    return time_received - send_request_ping_time<br><br>                # 数据包的超时时间判断<br>                timeout = timeout - wait_for_time<br>                if timeout &lt;= 0:<br>                    return -1</p><p>​<br>        def dealtime(dst_addr, sumtime, shorttime, longtime, accept, i, time):<br>            sumtime += time<br>            print(sumtime)<br>            if i == 4:<br>                print(“{0}的Ping统计信息：”.format(dst_addr))<br>                print(“数据包：已发送={0},接收={1}，丢失={2}（{3}%丢失），\n往返行程的估计时间（以毫秒为单位）：\n\t最短={4}ms，最长={5}ms，平均={6}ms”.format(i+1,accept,i+1-accept,(i+1-accept)/(i+1)*100,shorttime,longtime,sumtime))</p><p>​<br>        def ping(host):<br>            # 统计最终 已发送、 接受、 丢失<br>            send, accept, lost = 0, 0, 0<br>            sumtime, shorttime, longtime, avgtime = 0, 1000, 0, 0<br>            # TODO icmp数据包的构建<br>            # 8回射请求 11超时 0回射应答<br>            data_type = 8<br>            data_code = 0<br>            # 检验和<br>            data_checksum = 0<br>            # ID<br>            data_ID = 0<br>            # 序号<br>            data_Sequence = 1<br>            # 可选的内容<br>            payload_body = b’abcdefghijklmnopqrstuvwabcdefghi’ #data<br><br>            # 将主机名转ipv4地址格式，返回以ipv4地址格式的字符串，如果主机名称是ipv4地址，则它将保持不变<br>            dst_addr = socket.gethostbyname(host)<br>            print(“正在 Ping {0} [{1}] 具有 32 字节的数据:”.format(host, dst_addr))<br>            # 默认发送4次<br>            for i in range(0, 4):<br>                send = i + 1<br>                # 请求ping数据包的二进制转换<br>                icmp_packet = request_ping(data_type, data_code, data_checksum, data_ID, data_Sequence + i, payload_body)<br>                # 连接套接字,并将数据发送到套接字<br>                send_request_ping_time, rawsocket = raw_socket(dst_addr, icmp_packet)<br>                # 数据包传输时间<br>                times = reply_ping(send_request_ping_time, rawsocket, data_Sequence + i)<br>                if times &gt; 0:<br>                    print(“来自 {0} 的回复: 字节=32 时间={1}ms”.format(dst_addr, int(times*1000)))<br><br>                    accept += 1<br>                    return_time = int(times * 1000)<br>                    sumtime += return_time<br>                    if return_time &gt; longtime:<br>                        longtime = return_time<br>                    if return_time &lt; shorttime:<br>                        shorttime = return_time<br>                    time.sleep(0.7)<br>                else:<br>                    lost += 1<br>                    print(“请求超时。”)<br><br>                if send == 4:<br>                    print(“{0}的Ping统计信息:”.format(dst_addr))<br>                    print(“\t数据包：已发送={0},接收={1}，丢失={2}（{3}%丢失），\n往返行程的估计时间（以毫秒为单位）：\n\t最短={4}ms，最长={5}ms，平均={6}ms”.format(<br>                        i + 1, accept, i + 1 - accept, (i + 1 - accept) / (i + 1) * 100, shorttime, longtime, sumtime/send))</p><p>​<br>        if <strong>name</strong> == “<strong>main</strong>“:<br>            i = input(“请输入要ping的主机或域名\n”)<br>            ping(i)</p><h5 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h5><h6 id="SOCK-RAW"><a href="#SOCK-RAW" class="headerlink" title="SOCK_RAW"></a>SOCK_RAW</h6><p>实际上，我们常用的网络编程都是在应用层的报文的收发操作，也就是大多数程序员接触到的流式套接字(SOCK_STREAM)和数据包式套接字(SOCK_DGRAM)。而这些数据包都是由系统提供的协议栈实现，用户只需要填充应用层报文即可，由系统完成底层报文头的填充并发送。</p><p>然而在某些情况下需要执行更底层的操作，比如修改报文头、避开系统协议栈等。这个时候就需要使用其他的方式来实现。</p><p>原始套接字(SOCK_RAW)是一种不同于SOCK_STREAM、SOCK_DGRAM的套接字，它实现于系统核心。首先来说，普通的套接字无法处理ICMP、IGMP等网络报文，而SOCK_RAW可以；其次，SOCK_RAW也可以处理特殊的IPv4报文；此外，利用原始套接字，可以通过IP_HDRINCL套接字选项由用户构造IP头。总体来说，SOCK_RAW可以处理普通的网络报文之外，还可以处理一些特殊协议报文以及操作IP层及其以上的数据。</p><h2 id="引用自："><a href="#引用自：" class="headerlink" title="引用自："></a>引用自：</h2><pre><code>https://blog.csdn.net/zhj082/article/details/80531628https://www.jianshu.com/p/17f16256008d《计算机网络》第七版https://blog.csdn.net/newnewman80/article/details/8000404</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PING&quot;&gt;&lt;a href=&quot;#PING&quot; class=&quot;headerlink&quot; title=&quot;PING&quot;&gt;&lt;/a&gt;PING&lt;/h1&gt;&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h
      
    
    </summary>
    
    
      <category term="网络编程" scheme="https://sssmeb.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Python" scheme="https://sssmeb.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>网络编程基础</title>
    <link href="https://sssmeb.github.io/2019/06/12/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"/>
    <id>https://sssmeb.github.io/2019/06/12/网络编程基础/</id>
    <published>2019-06-12T04:08:13.000Z</published>
    <updated>2019-08-15T08:56:28.613Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>由于不同机器上的程序要通信，才产生了网络</p></blockquote><h1 id="111基础知识"><a href="#111基础知识" class="headerlink" title="111基础知识"></a>111基础知识</h1><h2 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h2><ol><li>应用类：qq、微信、网盘…（安装应用）</li><li>web类：百度、知乎、博客园…（浏览器访问）</li></ol><h3 id="C-S架构"><a href="#C-S架构" class="headerlink" title="C/S架构"></a>C/S架构</h3><ul><li>服务端（server）：一直运行，等待请求</li><li>客户端（client）：需要使用时，发送请求</li></ul><h3 id="B-S架构"><a href="#B-S架构" class="headerlink" title="B/S架构"></a>B/S架构</h3><p>基于浏览器（broser）。这是一个大的趋势（小程序、公众号），实际上就是统一入口。</p><ul><li>B/S架构实际上也是一种C/S架构。</li></ul><h2 id="物理相关知识"><a href="#物理相关知识" class="headerlink" title="物理相关知识"></a>物理相关知识</h2><h3 id="局域网内通信"><a href="#局域网内通信" class="headerlink" title="局域网内通信"></a>局域网内通信</h3><p>当两台计算机要进行通信，用网线连接两台计算机。网线是接通计算机的网卡，网卡上有 全球唯一的 mac地址。</p><p>（局域网内）当多台计算机要通信时，所有的计算机可以都用一条网线接到交换机上。</p><ul><li>通过ip地址，利用ARP协议找到对应的mac地址，进行连接传输。</li></ul><pre><code>地址解析协议，即ARP（数据链路层协议），是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。地址解析协议是建立在网络中各个主机互相信任的基础上的，网络上的主机可以自主发送ARP应答消息，其他主机收到应答报文时不会检测该报文的真实性就会将其记入本机ARP缓存；由此攻击者就可以向某一主机发送伪ARP应答报文，使其发送的信息无法到达预期的主机或到达错误的主机，这就构成了一个ARP欺骗。</code></pre><h3 id="广域网通信"><a href="#广域网通信" class="headerlink" title="广域网通信"></a>广域网通信</h3><p>通过路由器将多个局域网接通起来，而每个局域网都有一个统一的出口（网关）。</p><p>通过ip地址 和 子网掩码 按位与 得出本网段（可用于判断是否同为同一个网段）。</p><pre><code>子网掩码：255.255.255.0ip地址：192.168.13.253按位与：192.168.13.0</code></pre><h2 id="软件应用相关"><a href="#软件应用相关" class="headerlink" title="软件应用相关"></a>软件应用相关</h2><h2 id="软件应用相关-1"><a href="#软件应用相关-1" class="headerlink" title="软件应用相关"></a>软件应用相关</h2><h2 id="软件应用相关-2"><a href="#软件应用相关-2" class="headerlink" title="软件应用相关"></a>软件应用相关</h2><ul><li>服务使用 TCP或UDP的端口侦听客户端请求</li><li>客户端使用IP地址定位服务器 使用端口 定位服务</li><li>可以在服务器网卡上设置只开放必要的端口，实现服务器的网络安全</li></ul><h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><p>网络层向上提供简单灵活的、无连接的、尽最大努力交付的数据报服务。</p><h4 id="网际协议IP"><a href="#网际协议IP" class="headerlink" title="网际协议IP"></a>网际协议IP</h4><p>网际协议IP是TCP/IP体系中两个最主要的协议之一，也是最重要的互联网标准协议之一。</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561134369731&di=2b5159bdded1f222258c443f4e00191d&imgtype=0&src=http%3A%2F%2Fyzhtml01.book118.com%2F2016%2F11%2F16%2F18%2F43137046%2F10.files%2Ffile0001.png" alt="image"></p><ul><li>ARP协议在下，因为IP经常要使用它（PARP已淘汰）</li><li>ICMP、IGMP在上，它们要使用IP协议</li></ul><h6 id="ip分类"><a href="#ip分类" class="headerlink" title="ip分类"></a>ip分类</h6><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561136088813&di=0d5cdb76648fe45cbf20f6e4ddb8828d&imgtype=jpg&src=http%3A%2F%2Fimg1.imgtn.bdimg.com%2Fit%2Fu%3D615160441%2C3570589088%26fm%3D214%26gp%3D0.jpg" alt="image"> </p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561731432&di=aa2607837f79287a79623e1ead2ccb4d&imgtype=jpg&er=1&src=http%3A%2F%2Fup.2cto.com%2F2012%2F0314%2F20120314021819201.gif" alt="image"></p><h4 id="IP数据报的格式"><a href="#IP数据报的格式" class="headerlink" title="IP数据报的格式"></a>IP数据报的格式</h4><p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=889052176,1725627957&fm=26&gp=0.jpg" alt="image"></p><p>主要分为两部分</p><ul><li>固定长度 （20字节）</li><li>可选字节</li></ul><h5 id="各字段"><a href="#各字段" class="headerlink" title="各字段"></a>各字段</h5><ol><li>版本 4位 广泛使用ipv4、ipv6</li><li>首部长度 4位，而4位二进制数最大十进制是15，但固定长度是20字节。则将1乘4，所以此字段的最小值是5，最大值是60.若首部长度不是4的倍数时，利用最后的填充字段加以填充。</li><li>区分服务 一般不使用</li><li>总长度 指首部和数据之和，单位为字节。16位则最大长度位65535字节（很少这么长）</li><li>标识 16位。（并不是序号）因为ip是无连接服务，数据报不存在按序接收的问题。当数据报过长必须进行分片时，这个标识字段的值就被复制到所有的数据报片的标识字段中。相同的标识字段值使分片后的各数据报片最后能正确地重装成为原来的数据报。</li><li>标志 3位 目前只有两位有意义。MF（more fragment）=1表示还有分片，MF=0表示已经是最后一个。DF（don`t fragment）=0表示允许分片</li><li>片偏移 占13位，在分片后，某片在原分组中的相对位置。以8个字节为单位，即分片长度一定是8字节的整数倍。（规定分片长度不超过1420字节）<img src="https://img-blog.csdn.net/20160721091911560" alt="image"></li></ol><pre><code>分片一：标识：777，MF=1，DF=0,片偏移=0分片二：标识：777，MF=1,DF=0,片偏移=175分片三：标识：777，MF=0,DF=0,片偏移350</code></pre><ol start="8"><li>生存时间 8位 TTL（time to live）。防止无法交付的数据报无限制的在互联网。每跳一个路由器减一，当为0时，路由器丢弃该数据报。</li><li>协议 8位。指出此数据报携带的数据是使用何种协议，以便知道该上交给哪个协议进行处理。</li></ol><table><thead><tr><th>协议名</th><th>ICMP</th><th>IGMP</th><th>IP(ip数据报再封装ip数据报)</th><th>TCP</th><th>UDP</th><th>IPv6</th></tr></thead><tbody><tr><td>协议字段值</td><td>1</td><td>2</td><td>4</td><td>6</td><td>17</td><td>41</td></tr><tr><td>10. 首部检验和 16位。只检验数据报首部。二进制反码求和。</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>11. 源地址 32位</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>12. 目的地址 32位</td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><h5 id="分组转发"><a href="#分组转发" class="headerlink" title="分组转发"></a>分组转发</h5><ol><li>从数据报首部提取目的主机的IP地址，得出网络地址</li><li>若再同网段则直接交付（包括把目的地址转化位硬件地址）</li><li>若路由表中有目的地址的特定主机路由（特定指明的），则指明下一跳</li><li>若路由表有到达目的网络的路由，则指明下一跳</li><li>若有默认路由则发送给默认路由</li><li>报告转发分组出错</li></ol><p>注：路由表中并不是指明到达某网络的完整路径，而只是下一跳路径。</p><h3 id="运输层"><a href="#运输层" class="headerlink" title="运输层"></a>运输层</h3><h4 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h4><p>接通两台计算机后，需要确定与哪个应用程序进行通信。而每一个需要网络通信的程序都会在本机上开一个端口。（同一时间同一台计算机，一个端口只被一个程序占用。）</p><pre><code>单个计算机中进程是用进程标识符来标志的。但在互联网环境下，不同的计算机可能使用不同的操作系统，不同的操作系统又使用不同格式的进程标识符。为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法对TCP/IP体系的应用进程进行标志。解决这个问题的方法就是在运输层使用协议端口号。</code></pre><h5 id="端口号范围：0-65535"><a href="#端口号范围：0-65535" class="headerlink" title="端口号范围：0-65535"></a>端口号范围：0-65535</h5><ul><li>0~1023是系统端口号。指派给了TCP/IP最重要的一些应用程序</li><li>1024~49151是登记端口号。是为没有熟知端口号的应用程序使用的。这类端口号必须在IANA按照规定登记，以防止重复。</li><li>49152~65535是客户端使用的端口号，又叫做短暂端口号。这类端口号留给客户进程选择暂时使用。当通信结束后，客户端已使用过的端口号就不复存在了。</li></ul><h5 id="常见端口号"><a href="#常见端口号" class="headerlink" title="常见端口号"></a>常见端口号</h5><table><thead><tr><th>端口</th><th>协议</th></tr></thead><tbody><tr><td>53</td><td>DNS域名系统协议</td></tr><tr><td>80</td><td>超文本传输协议（HTTP）</td></tr><tr><td>443</td><td>安全超文本传输协议（HTTPS）</td></tr><tr><td>21</td><td>FTP文件传输协议</td></tr><tr><td>22</td><td>安全外壳协议（SSH）</td></tr><tr><td>53（UDP）</td><td>DNS</td></tr><tr><td>3306</td><td>mysql</td></tr></tbody></table><h4 id="TCP协议（全双工通信、可靠、面向连接）"><a href="#TCP协议（全双工通信、可靠、面向连接）" class="headerlink" title="TCP协议（全双工通信、可靠、面向连接）"></a>TCP协议（全双工通信、可靠、面向连接）</h4><blockquote><p>全双工即通信允许数据在两个方向上、同时传输（半双工则不可同时）</p></blockquote><h5 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h5><ol><li>TCP是面向连接的运输层协议。在使用TCP协议之前，必须先建立TCP连接。数据传送完毕后必须释放已经建立的连接。</li><li>每条连接只能点对点</li><li>可靠交付</li><li>全双工（两端都设有发送缓存和接收缓存）</li><li>面向字节流（流入到进程或从进程流出的字节序列）</li></ol><p>TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节。（UDP发送的报文长度是应用进程给出的）。如果应用进程传送到TCP缓存的数据块太长，TCP就可以把它划分短一些再传送。如果应用进程一次只发来一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。</p><h5 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h5><p>TCP连接有两个端点，而这个端点叫套接字。每条TCP连接唯一地被通信两端的两个端点（套接字）所确定。</p><pre><code>套接字 socket = ( IP地址 : 端口号)</code></pre><h5 id="可靠传输"><a href="#可靠传输" class="headerlink" title="可靠传输"></a>可靠传输</h5><p>TCP下面的网络所提供的是不可靠的传输，因此，TCP必须采用适当的措施才能使得两个运输层之间的通信变得可靠。</p><p>理想传输条件：</p><ol><li>传输信道不产生差错</li><li>不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。</li></ol><h6 id="停止等待协议"><a href="#停止等待协议" class="headerlink" title="停止等待协议"></a>停止等待协议</h6><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561029747260&di=7544cf1b89f9d71f8b793eaeb5b12e2a&imgtype=jpg&src=http%3A%2F%2Fimg4.imgtn.bdimg.com%2Fit%2Fu%3D22323794%2C3375435270%26fm%3D214%26gp%3D0.jpg" alt="image"></p><p>最简单的用来保证可靠传输的协议，再每发送完一个分组时设定一个超时计时器，实现超时重传。</p><p>但是信道利用率低！信道绝大多数时间都是等待空闲的。</p><h6 id="连续ARQ协议"><a href="#连续ARQ协议" class="headerlink" title="连续ARQ协议"></a>连续ARQ协议</h6><p>滑动窗口协议是TCP协议的精髓所在。</p><p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=4072979376,3641484915&fm=26&gp=0.jpg" alt="image"></p><ul><li>发送方连续发送分组，每收到一个确认，就把发送窗口向前滑动一个分组的位置。</li><li>接收方一般采用累积确认的方式。不必收到每个分组都逐一确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认。</li></ul><pre><code>缺点是不能向发送方反映接收方已经正确收到的所有分组信息例如发送方发送了前5个分组，但只有第3个丢失了。这时接收方只能对前两个分组发送确认，发送方无法知道后面3个分组的情况，必须重新发送后面三个分组。这就叫做Go-back-N 回退N</code></pre><h5 id="TCP报文段的首部格式"><a href="#TCP报文段的首部格式" class="headerlink" title="TCP报文段的首部格式"></a>TCP报文段的首部格式</h5><p>TCP报文段氛围首部和数据两部分，而TCP的全部功能都体现在它的首部中各字段的作用。</p><p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=2627348429,2184604078&fm=26&gp=0.jpg" alt="image"></p><p>报文段首部的前20个字节是固定的</p><ol><li>源端口和目的端口（各2个字节）</li><li>序号 占4个字节，即2^32个序号(TCP是面向字节流的，传送中每一个字节都按顺序编号。该序号字段值表示本报文所发送的数据的第一个字节的序号)</li><li>确认号 期望收到对方下一个报文段的第一个数据字节的序号。即表示N-1为止的数据已收到。</li><li>数据偏移 实际上就是TCP报文段的首部长度。4位，但是单位是32位即4个字节。4位的最大十进制数是15，所以数据偏移的最大值是60，即是TCP首部的最大长度。（即选项长度不能超过40）</li><li>保留6位今后使用</li><li>URG urgent紧急字段。相当于高优先级。（但是大量的开发者都将它置为1，导致用处不明显。）</li><li>ACK 当ACK=1时确认好字段才有效。建立连接后ACK都必须置为1.</li><li>RST reset表明TCP连接中出现严重差错，必须释放连接，然后再重新建立运输连接。</li><li>SYN 建立连接时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。若对方同意建立连接，则在响应报文中使用 SYN=1 ACK=1 .因此SYN置为1就表示这是一个连接请求或连接接受报文。</li><li>FIN 用来释放连接。</li><li>窗口 占2字节。指的是发送本报文段的一方的接收窗口。用来告诉对方：从本报文段首部中的确认好算起，接收方目前允许对方发送的数据量。即作为接收方让发送方设置其发送窗口的依据。</li><li>检验和 包括首部和数据这两部分进行检验。同UDP需要伪首部（其中第4个字段17改位6）</li><li>紧急指针 当URG=1时，指明紧急数据中的字节数（紧急数据后就是普通数据）。当窗口为0时也可以发送紧急数据。</li></ol><h5 id="TCP可靠传输的实现"><a href="#TCP可靠传输的实现" class="headerlink" title="TCP可靠传输的实现"></a>TCP可靠传输的实现</h5><h6 id="缓存机制"><a href="#缓存机制" class="headerlink" title="缓存机制"></a>缓存机制</h6><p>TCP的滑动窗口是以字节为单位的。凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传使用。</p><p><img src="https://img-blog.csdn.net/20160913091424535" alt="image"></p><p>发送缓存用来展示存放：</p><ol><li>发送应用程序传送给发送方TCP准备发送的数据</li><li>TCP已发送但未收到确认的数据</li></ol><p><img src="https://img-blog.csdn.net/20160913092647729" alt="image"><br>接收缓存用来暂时存放：</p><ol><li>按序到达、但尚未被接收应用程序读取的数据</li><li>未按序到达的数据</li></ol><h6 id="超时重传时间的选择"><a href="#超时重传时间的选择" class="headerlink" title="超时重传时间的选择"></a>超时重传时间的选择</h6><p>TCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间RTT。再进行加权平均，每测得一个新样本就更新一次RTTs。</p><h5 id="TCP流量控制"><a href="#TCP流量控制" class="headerlink" title="TCP流量控制"></a>TCP流量控制</h5><p>所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。</p><ul><li>利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制</li></ul><h6 id="传输效率"><a href="#传输效率" class="headerlink" title="传输效率"></a>传输效率</h6><p>在TCP实现中广泛使用Nagle算法：</p><pre><code>若发送应用进程把要发送的数据逐个字节地送到TCP的发送缓存则发送方就把第一个字节先发送出去，其他数据先缓存（避免了浪费大量的带宽而发送失败）待收到确认后，再把所有数据组装成一个报文段发送出去。且当达到的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。（有效的提高网络的吞吐量）</code></pre><p>糊涂窗口综合征</p><pre><code>当TCP接收方缓存已满，应用程序一次只读取一个字节的缓存则发送方一次只能发送一个字节导致网络效率低下可以让接收方等待一段时间，或者等待接收方缓存已有一半空闲的时间接收方就发送确认报文。</code></pre><h5 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h5><h6 id="拥塞控制与流量控制？"><a href="#拥塞控制与流量控制？" class="headerlink" title="拥塞控制与流量控制？"></a>拥塞控制与流量控制？</h6><p>拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器以及网络传输性能相关的所有因素。</p><p>相反，流量控制往往是指点对点通信量的控制，是个端到端的问题（接收端控制发送端）</p><p>某些拥塞控制算法是向发送端发送控制报文，并告诉发送端，网络已出现麻烦，必须放慢发送速率。这点又和流量控制是很相似的。</p><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561110490888&di=657acc0db39c23773d7b4d399616e706&imgtype=jpg&src=http%3A%2F%2Fimg0.imgtn.bdimg.com%2Fit%2Fu%3D1602021445%2C2155737783%26fm%3D214%26gp%3D0.jpg" alt="image"></p><p>闭环控制的三种措施：</p><ol><li>拥塞检测</li><li>拥塞通告</li><li>拥塞缓解</li></ol><h6 id="TCP的拥塞控制"><a href="#TCP的拥塞控制" class="headerlink" title="TCP的拥塞控制"></a>TCP的拥塞控制</h6><ul><li>慢开始</li><li>拥塞避免</li><li>快重传</li><li>快恢复</li></ul><h6 id="慢开始和拥塞避免"><a href="#慢开始和拥塞避免" class="headerlink" title="慢开始和拥塞避免"></a>慢开始和拥塞避免</h6><p>刚开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么久有可能引起网络发生拥塞。较好的方法就是先探测一下，由小到大逐渐增大发生窗口</p><p>每经过一个传输轮次，拥塞窗口cwnd就加倍。（发生方每接收到一个对新报文的确认就立即为其窗口加1，不需要等待整个轮次结束。）</p><p><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2659599350,2767325847&fm=26&gp=0.jpg" alt="image"></p><p>当网络出现超时，发送方判断为网络拥塞，于是调整门限值(cwnd/2)，同时窗口值cwnd设置为1，进入慢开始阶段。</p><p>有时各别报文段丢失，而并非网络拥塞，但却启动慢重传会降低传输效率。于是采用快重传算法。接收方不要等待自己发送数据时才捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到报文段的重复确认。</p><pre><code>当已接收m1,m2，未接收m3但接收到m4时接收方除了会分别发送确认，还必须立即发送对m2的重复确认发送方一连收到3个重复确认就知道接收方没有收到报文m3立即进行重传。而不会出现超时快重传使整个网络的吞吐量提高约20%</code></pre><p>对于以上只是丢失了个别的报文段，于是不启动慢开始，而是执行快恢复。发送方门限值设置为cwnd/2， 拥塞窗口同设置为cwnd/2</p><p>总结为：</p><p><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=2418067993,793264225&fm=26&gp=0.jpg" alt="image"></p><h5 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h5><p><img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=494606616,1423612774&fm=26&gp=0.jpg" alt="image"></p><ol><li>客户端首先发送SYN请求，seq作为序列号标识，如果对方应答则返回 x+1。</li><li>因为是全双工通信，所以服务器接收到客户端的SYN后，不仅要回复确认ack，同时也要请求客户端的通信许可，即也回发一个SYN。</li><li>成功建立TCP连接。</li></ol><p>（TCP标准规定，ACK报文段可以携带数据，但如果不携带数据则不消耗序号）</p><p>为什么A最后还要发送一次确认呢？</p><pre><code>假定出现这种情况：A发出的第一个请求报文在某处滞留，A没有收到确认于是再次发生连接请求。第二次数据传输完成后，关闭了连接。此时B收到第一个滞留的请求，于是回复。若没有A的第二次确认，则此连接一直占用，资源浪费</code></pre><h5 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h5><h5 id="四次挥手-1"><a href="#四次挥手-1" class="headerlink" title="四次挥手"></a>四次挥手</h5><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1559907870440&di=e1b6bcd1318769bcb2db000b2e5668d0&imgtype=0&src=http%3A%2F%2Fwww.pc-fly.com%2Fuploads%2Fallimg%2F20170516%2F1494943585801_2.jpg" alt="image"><br>结束的请求可以由客户端发起，也可以由服务端发起。</p><p>例：</p><ol><li>客户端发起结束连接的请求，则由客户端向服务端的通道先断开。（进入FIN-WAIT-1）</li><li>服务端同意客户端的断开。（进入FIN-WAIT-2）</li><li>服务器继续发送未完成的报文</li><li>服务器请求断开。</li><li>客户端同意断开。（等待两个来回时间，若无服务器请求，则正常关闭）</li></ol><p>（TCP标准规定，FIN报文即使不携带数据，也消耗掉一个序号）</p><h5 id="为什么握手三次，挥手需要四次？"><a href="#为什么握手三次，挥手需要四次？" class="headerlink" title="为什么握手三次，挥手需要四次？"></a>为什么握手三次，挥手需要四次？</h5><p>首先握手实际上也可以分为四次，只是在第二次握手时，把确认和请求一起发送了。</p><p>建立连接时可以同时发送，但是断开连接时情况不同。当一方请求断开连接时，另一端可能还有数据没有传输完成，所以此时不会将 确认对方断开 和 请求自己断开 合并一起发送（两次挥手合并为一次）。</p><p><a href="https://www.cnblogs.com/thrillerz/p/6464203.html" target="_blank" rel="noopener">生动讲解四次挥手</a></p><ul><li>FIN_WAIT_1:</li></ul><pre><code>其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态。当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方）</code></pre><ul><li>FIN_WAIT_2：</li></ul><pre><code>实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方）</code></pre><ul><li>CLOSE_WAIT：</li><li>CLOSE_WAIT：</li></ul><pre><code>这种状态的含义其实是表示在等待关闭。当对方close一个SOCKET后发送FIN报文给自己，你会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来，当数据全部传输结束后，那么就可以close这个SOCKET。发送FIN报文给对方，也即关闭连接。所以在CLOSE_WAIT状态下，对方需要完成的事情是等待你去关闭连接。</code></pre><ul><li>LAST_ACK: </li></ul><pre><code>它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方）</code></pre><ul><li>TIME_WAIT: </li><li>TIME_WAIT: </li></ul><pre><code>表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）如果2个来回时间内，再次收到了对方发来的请求断开FIN，则说明前面发送的确认报文丢失，再次发送。</code></pre><h4 id="UDP（无连接、不可靠、面向报文）"><a href="#UDP（无连接、不可靠、面向报文）" class="headerlink" title="UDP（无连接、不可靠、面向报文）"></a>UDP（无连接、不可靠、面向报文）</h4><h4 id="UDP（无连接、不可靠、面向报文）-1"><a href="#UDP（无连接、不可靠、面向报文）-1" class="headerlink" title="UDP（无连接、不可靠、面向报文）"></a>UDP（无连接、不可靠、面向报文）</h4><p>不可靠的无连接传输，需要发送数据时，直接发往对方。</p><p>优点： 快、不需要占用连接资源</p><h5 id="UDP特点"><a href="#UDP特点" class="headerlink" title="UDP特点"></a>UDP特点</h5><ul><li>无连接，减少了开销和发送数据之前的时延</li><li>不可靠交付，尽最大努力交付，因此主机不需要维持复杂的连接状态。</li><li>面向报文。UDP对应用层交下来的报文，既不合并也不拆分，而是保留这些报文的边界。（应用层交付给UDP多长的报文，UDP就照样发送，一次一个报文。）</li><li>没有拥塞控制，即使出现网络拥塞也不会降低发送速率，这对实时应用很重要（ip电话，视频会议）。</li><li>支持一对一、一对多、多对一、多对多交互通信。</li><li>首部开销小，只有8个字节。TCP20个字节。</li></ul><h5 id="UDP首部格式"><a href="#UDP首部格式" class="headerlink" title="UDP首部格式"></a>UDP首部格式</h5><ul><li>数据字段</li><li>首部字段（8字节）<ol><li>源端口</li><li>目的端口</li><li>长度（UDP用户数据报的长度，最小值为8即只有首部）</li><li>检验和</li></ol></li></ul><p><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561016650721&di=1cd9be678d9e3c1fb8df64f726be2fc4&imgtype=0&src=http%3A%2F%2Fpic002.cnblogs.com%2Fimages%2F2012%2F387401%2F2012070915501298.png" alt="image"></p><p>（伪首部是一个虚拟的数据结构，其中的信息是从数据报所在IP分组头的分组头中提取的。既不向下传送也不向上递交，而仅仅是为了计算检验和。）</p><pre><code>为什么伪首部要有目的IP地址学习过通信系统原理后，我们知道数据传输过程中会产生误码，0可能变为1，1可能变为0，并且每种校验码都有一定的查错能力，超过这个范围，就无法察觉错误了，而早期的通信环境大概比较糟糕，因此，在传输过程中出现误码，可能使IP报文的目的地址出现错误，接收主机的UDP计算校验和时，目的IP地址来自IP层，由于目的IP地址出现错误，导致发送主机计算检验和时使用的目的IP地址与接收主机计算检验和时使用的目的IP地址不同，UDP发现错误，丢弃报文</code></pre><p>​<br>​<br>​    为什么伪首部要有源IP地址<br>​<br>    为了让接收主机确认源IP地址没有出现错误。</p><pre><code>假设我们想要开发一款基于UDP的程序，A发送UDP报文给B，B要发送回应报文给A，假设传输过程出现误码，源IP地址出现错误，则A计算检验和时使用的源IP地址与B计算校验和时使用的源IP地址不同，B就可以发现错误，从而丢弃报文，定时重传等可靠性由应用程序自己保证</code></pre><blockquote><p><a href="https://blog.csdn.net/dhaiuda/article/details/80623150" target="_blank" rel="noopener">https://blog.csdn.net/dhaiuda/article/details/80623150</a></p></blockquote><h5 id="应用场景："><a href="#应用场景：" class="headerlink" title="应用场景："></a>应用场景：</h5><pre><code>DNS域名解析就是使用UDP（绝大多数）qq聊天功能实际上就是利用udp。因为如果聊天功能使用TCP传输则当和多个人聊天时，需要建立多条连接，持续占用。但是类似的聊天功能会在代码层面进行传输检查，所以我们可以知道某些信息发送失败了。多播、广播</code></pre><h2 id="编程基础"><a href="#编程基础" class="headerlink" title="编程基础"></a>编程基础</h2><h2 id="编程基础-1"><a href="#编程基础-1" class="headerlink" title="编程基础"></a>编程基础</h2><h2 id="编程基础-2"><a href="#编程基础-2" class="headerlink" title="编程基础"></a>编程基础</h2><h3 id="socket"><a href="#socket" class="headerlink" title="socket"></a>socket</h3><p>socket是应用层与传输层通信的中间软件抽象层，它是一组接口。把复杂的TCP/IP协议族隐藏在socket接口后面，用户只需要操作简单的接口即可，socket会去组织数据，以符合指定的协议。</p><blockquote><p>socket 套接字 （ip + port）</p></blockquote><ul><li>AF_UNIX : 【少用】（在unix中一切皆文件）基于文件的套接字。两个套接字进程运行在同一机器，可以通过访问同一个文件系统间接完成通信。</li><li>AF_INET : 基于网络（ipv4）。还有AF_INET6被用于ipv6。</li></ul><h4 id="socket建立tcp连接（基于数据流）"><a href="#socket建立tcp连接（基于数据流）" class="headerlink" title="socket建立tcp连接（基于数据流）"></a>socket建立tcp连接（基于数据流）</h4><p><img src="https://img-blog.csdn.net/20180418113907183?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NvbWVkYXkxMzE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p><ul><li>server.py</li></ul><pre><code>import socketsk = socket.socket()        # 实例化一个socket# 有些操作系统可能在端口使用完后不会马上回收，当重启服务时可能会导致端口占用。# sk.setsockopt(socket.SOL_SOCKET, socket.SO_REUSERADDR, 1)sk.bind((&apos;127.0.0.1&apos;, 8980))# 绑定ip、端口. 注：以元组的形式sk.listen()                 # 监听conn, addr = sk.accept()    # 阻塞等待连接， 获得连接对象、对方的地址（接口内部完成三次握手）ret = conn.recv(1024)       # 阻塞等待接受数据流 1024字节conn.send(b&apos;hi&apos;)            # 传送数据，只支持字节conn.close()                # 关闭连接（接口内部完成四次挥手）sk.close()                  # 关闭套接字</code></pre><ul><li>client.py</li></ul><pre><code>import socketsk = socket.socket()        # 实例化一个socketsk.connect((&apos;127.0.0.1&apos;, 8980))  # 绑定想连接的ip、端口# client端不需要获取连接对象sk.send(b&apos;hello&apos;)           # 发送数据ret = sk.recv()             # 接受数据sk.close()</code></pre><p>黏包现象：由于面向连接，例当recv(1024)没接收完当前数据，可能会导致本次剩余的数据到下一次recv接收。（基于tcp的拆包分组机制）</p><p>当server与client1连通后，执行另一个client2连接。由于tcp的面向连接的，当前连接会占用资源，此时client2会进入等待状态，直至server断开与client1的连接，则client2才能与server建立连接。</p><h5 id="解决黏包问题"><a href="#解决黏包问题" class="headerlink" title="解决黏包问题"></a>解决黏包问题</h5><p>为什么会出现黏包现象？</p><pre><code>首先只有在TCP协议中才会出现黏包现象，是因为TCP协议是面向流的协议，在发送数据传输过程中还有缓存机制来避免数据丢失。因此，在连续发送小数据的时候、以及接收大小不符的时候都容易出现黏包现象。本质还是因为我们在接收数据的时候不知道发送的数据长短。</code></pre><p>怎么解决问题？</p><pre><code>在传输大量数据之前先告诉接收端要发送的数据大小如果要优化的话，可以使用struct模块来定制协议。</code></pre><p>黏包例子:</p><pre><code># 第一次接收ret = conn.recv(2)# 第二次接收ret = conn.recv(10)</code></pre><p>当第一次接收未完成时，剩下的数据（存放在接收端的缓存区）可能会跟着第二次接收的内容一起被接收。导致数据错乱。</p><p>同理可能还会出现： （tcp传输会进行切片，如果两数据较小，可能会组成一块，一起发送。）</p><pre><code># client 连续send 若中间有其他操作 可能就不会出现conn.send(b&apos;ab&apos;)conn.send(b&apos;c&apos;)# serverret = conn.recv(10)ret.encode() # abc</code></pre><p>所以问题的本质是：<strong>不知道接收的数据大小导致了黏包。</strong></p><p>则解决方法是：先发送数据的大小(len())，接收端按长度接收。</p><pre><code># 发生端 sk.send(str(len(s1)+len(s2).encode())sk.recv(1024)   # oksk.send(s1)sk.send(s2)# 接收端num = conn.recv(1024).decode()conn.send(b&apos;ok&apos;)res = conn.recv(int(num)).decode()</code></pre><p>中间多加一步ok是因为，接收端不知道num的长度，如果发送方直接发送数据，可能会和num的包一起发送出去，又造成黏包现象。</p><ul><li>优点：确定了每次要接收数据的大小</li><li>缺点：多了一次交互</li></ul><p>以上多一次交互的原因是由于不知道数据长度的长度（num的长度）。使用struct优化。</p><ul><li>struct：可以把一种类型转化为固定长度的byte（例如本处需要把数字转化）</li></ul><pre><code># 发送端import structnum = str(len(s1)+len(s2)num_byte = struct.pack(&apos;i&apos;, num)sk.send(num_byte)   # 直接连续3次sendsk.send(s1)     sk.send(s2)# 接收端num = conn.recv(4)  # 已知固定长度为4num = struct.unpack(&apos;i&apos;, num)[0]    # 同样的方式解开，得到数据的长度res = conn.recv(int(num)).decode()</code></pre><p><img src="https://images2015.cnblogs.com/blog/917108/201609/917108-20160911144809418-406479646.png" alt="image"><br><img src="https://images2015.cnblogs.com/blog/917108/201609/917108-20160911144809418-406479646.png" alt="image"></p><h6 id="会连续send吗？"><a href="#会连续send吗？" class="headerlink" title="会连续send吗？"></a>会连续send吗？</h6><p>连续send的情况还是比较常见的，例如传输大文件时，都是边读边传，边收边写。以下情况是双方都固定4096个字节，所以不会发生黏包现象。</p><pre><code># rb 按字节读f = open(filename, &apos;rb&apos;)while True:    # 缓存大小为4096字节    msg = f.read(4096)    if not msg:        break    cliSockfd.sendall(msg)f.close()time.sleep(1)cliSockfd.sendall(&apos;EOF&apos;.encode())f = open(filename, &apos;wb&apos;)while True:    msg = cliSockfd.recv(4096).decode()    if msg == &apos;EOF&apos;:        print(&apos;recv file success!&apos;)        break    f.write(msg.encode())f.close</code></pre><h4 id="socket建立udp连接（基于数据包）"><a href="#socket建立udp连接（基于数据包）" class="headerlink" title="socket建立udp连接（基于数据包）"></a>socket建立udp连接（基于数据包）</h4><h4 id="socket建立udp连接（基于数据包）-1"><a href="#socket建立udp连接（基于数据包）-1" class="headerlink" title="socket建立udp连接（基于数据包）"></a>socket建立udp连接（基于数据包）</h4><p><img src="https://img-blog.csdn.net/20180418113940410?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NvbWVkYXkxMzE0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p><ul><li>server.py</li></ul><pre><code># udp不需要监听、建立连接import socketsk = socket.socket(type=socket.SOCK_DGRAM)        # datagram 数据报文sk.bind((&apos;127.0.0.1&apos;, 8980))# 需要先被动等待msg, addr = sk.recvfrom(1024)# 发送时要带上源地址sk.sendto(b&apos;bye&apos;, addr)</code></pre><ul><li>client.py </li><li>client.py </li></ul><pre><code>import socketsk = socket.socket(type=socket.SOCK_DGRAM)ip_port = (&apos;127.0.0.1&apos;, 8980)sk.sendto(b&apos;hello&apos;, ip_port)msg,addr = sk.recvfrom(1024)sk.close()</code></pre><p>udp不会出现黏包现象，但是有可能丢包<br>udp不会出现黏包现象，但是有可能丢包</p><h2 id="进阶编程"><a href="#进阶编程" class="headerlink" title="进阶编程"></a>进阶编程</h2><h3 id="简单客户端验证"><a href="#简单客户端验证" class="headerlink" title="简单客户端验证"></a>简单客户端验证</h3><pre><code>import hmac     # 类似hashilibh = hmac.new()密文 = h.digest()hmac.compare_digest(x1, x2)   # 对比 密文-另外一个密文</code></pre><p>双方已知的密钥的前提下，双方都通过密钥加密同一数据，通过对比是否相同，从而判断是否过验。</p><pre><code>import socketimport hmacsecret_key = &apos;egg&apos;sk = socket.socket()sk.bind((&apos;127.0.0.1&apos;, 8980))sk.listen()def check_conn(conn):    msg = os.urandom(32)    # 生成随机32位字符    conn.send(msg)          # 发送给客户端进行加密    h = hmac.new(secret_key, msg)   # 服务端自己加密    digest = h.digest()         # 获得密文    client_digest = conn.recv(1024) # 获取客户端加密的密文    return hmac.compare_digest(digest, client_digest)   # 对比两密文是否一致</code></pre><p>​<br>​    # 客户端<br>​    import hmac<br>​    import socket<br>​    secret_key = ‘egg’          # 同一密钥<br>​    sk = socket.socket()<br>​    sk.connect((‘127.0.0.1’, 8980))<br>​    msg = sk.recv(1024)<br>​    h = hmac.new(secret_key, msg)<br>​    digest = h.digest()<br>​    sk.send<br>​<br>    sk.close()</p><p>FTP和SMTP<br>FTP和SMTP<br>FTP和SMTP<br>FTP和SMTP</p><ol start="3"><li>我们已经有了FTP后，为何在邮件服务器之间传输邮件(邮件也是一种文件)时，还需要SMTP协议？以及为何需要HTTP协议</li></ol><p>SMTP 是一种提供可靠且有效电子邮件传输的协议。 SMTP 是建模在 FTP 文件传输服务上的一种邮件服务，主要用于传输系统之间的邮件信息并提供来信有关的通知。</p><p>SMTP 独立于特定的传输子系统，且只需要可靠有序的数据流信道支持。 SMTP 重要特性之一是其能跨越网络传输邮件，即“ SMTP 邮件中继”。通常，一个网络可以由公用互联网上 TCP 可相互访问的主机、防火墙分隔的 TCP/IP 网络上 TCP 可相互访问的主机，及其它 LAN/WAN 中的主机利用非 TCP 传输层协议组成。使用 SMTP ，可实现相同网络上处理机之间的邮件传输，也可通过中继器或网关实现某处理机与其它网络之间的邮件传输。</p><p>在这种方式下，邮件的发送可能经过从发送端到接收端路径上的大量中间中继器或网关主机。域名服务系统（DNS）的邮件交换服务器可以用来识别出传输邮件的下一跳 IP 地址。 </p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p><a href="https://blog.csdn.net/caogenwangbaoqiang/article/details/79997787" target="_blank" rel="noopener">link</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;由于不同机器上的程序要通信，才产生了网络&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;111基础知识&quot;&gt;&lt;a href=&quot;#111基础知识&quot; class=&quot;headerlink&quot; title=&quot;111基础知识&quot;&gt;&lt;/a&gt;111基础知识&lt;/h
      
    
    </summary>
    
    
      <category term="网络编程" scheme="https://sssmeb.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Python" scheme="https://sssmeb.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Flask源码解析</title>
    <link href="https://sssmeb.github.io/2019/05/12/Flask%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>https://sssmeb.github.io/2019/05/12/Flask源码解析/</id>
    <published>2019-05-12T09:26:49.000Z</published>
    <updated>2019-08-15T08:56:17.924Z</updated>
    
    <content type="html"><![CDATA[<h1 id="两个核心依赖"><a href="#两个核心依赖" class="headerlink" title="两个核心依赖"></a>两个核心依赖</h1><p>falsk主要依赖两个库 —— Werkzeug 和 Jinja。</p><h2 id="Jinja2"><a href="#Jinja2" class="headerlink" title="Jinja2"></a>Jinja2</h2><p>由于大多数Web程序都需要渲染模板，与Jinja2集成可以减少大量的工作。此处不展开讨论。</p><h2 id="Werkzeug"><a href="#Werkzeug" class="headerlink" title="Werkzeug"></a>Werkzeug</h2><p><strong>Flask的核心扩展就是Werkzeug。</strong></p><p>python Web框架都需要处理WSGI交互，它是为了让Web服务器与python程序能够进行数据交流而定义的一套==接口标准/规范==。而Werkzeug是一个优秀的WSGI工具库。</p><pre><code>HTTP请求 -》 WSGI规定的数据格式 -》 Web程序</code></pre><p>从路由处理，到请求解析，再到响应封装，以及上下文和各种数据结构都离不开Werkzeug。</p><img src="https://ss0.baidu.com/6ONWsjip0QIZ8tyhnq/it/u=3497197836,1903906446&fm=173&s=C0231E741767451B4460D8DD020090B1&w=638&h=639&img.JPEG" width="400" hegith="300"><h3 id="WSGI程序"><a href="#WSGI程序" class="headerlink" title="WSGI程序"></a>WSGI程序</h3><p>根据WSGI的规定，Web程序（WSGI程序）必须是一个可调用对象。这个可调用对象接收两个参数：</p><ul><li>environ：包含了请求的所有信息的字典。</li><li>start_response：需要在可调用对象中调用的函数，用来发起响应，参数是状态码，响应头部等</li></ul><p>WSGI服务器会在调用这个可调用对象时传入这两个参数。另外这个可调用对象还要返回一个可迭代对象。</p><p>这个可调用对象可以是函数、方法、类或是实现了<strong>call</strong>方法的类实例。</p><p>以下借助简单的实例来了解最主要的两种实现：函数和类</p><pre><code># 函数实现# 可调用对象    接收两个参数def hello(environ, start_response):    # 响应信息    status = &apos;200 OK&apos;    response_headers = [(&apos;Content-type&apos;, &apos;text/html&apos;)]    # 需要在可调用函数中调用的函数    start_response(status, response_headers)    # 返回可迭代对象    return [b&apos;&lt;h1&gt;Hello&lt;/h1&gt;&apos;]</code></pre><blockquote><p>注：WSGI规定请求和响应主体应该为字符串(bytestrings)，即py2中的str。在py3中字符串默认为unicode类型，因此需要在字符串前添加b声明为bytes类型,兼容两者</p></blockquote><pre><code># 类实现class AppClass:    def __init__(self, environ, start_response):        self.environ = environ        self.statr = start_response    # iter方法，这个类被迭代时，调用这个方法    # 实现该方法的类就是迭代器    def __iter__(self):        status = &apos;200 OK&apos;        response_headers = [(&apos;Content-type&apos;, &apos;text/html&apos;)]        self.start(status, response_headers)        yield b&apos;&lt;h1&gt;Hello&lt;/h1&gt;&apos;</code></pre><h4 id="werkzeug中如何实现Web程序"><a href="#werkzeug中如何实现Web程序" class="headerlink" title="werkzeug中如何实现Web程序"></a>werkzeug中如何实现Web程序</h4><p>由于flask是基于werkzeug实现的，所以先了解以下werkzeug是如何实现一个简单的web程序</p><pre><code>from werkzeug.wrappers import Request, Response@Request.applicationdef hello(request):    return Response(&apos;hello&apos;)if __name__ == &apos;__main__&apos;:    from werkzeug.serving import run_simple    run_simple(&apos;localhost&apos;, 5000, hello)</code></pre><p>通过以上代码，使用<strong>run_simple</strong>规定了ip、端口号、调用对象</p><h1 id="路由是怎么设定的？"><a href="#路由是怎么设定的？" class="headerlink" title="路由是怎么设定的？"></a>路由是怎么设定的？</h1><h2 id="Werkzeug怎么实现路由系统"><a href="#Werkzeug怎么实现路由系统" class="headerlink" title="Werkzeug怎么实现路由系统"></a>Werkzeug怎么实现路由系统</h2><pre><code># 路由表m = Map()rule1 = Rule(&apos;/&apos;, endpoint=&apos;index&apos;)rule2 = Rule(&apos;/downloads/&apos;, endpoint=&apos;downloads/index&apos;)m.add(rule1)m.add(rule2)</code></pre><h2 id="Flask的路由系统"><a href="#Flask的路由系统" class="headerlink" title="Flask的路由系统"></a>Flask的路由系统</h2><p>Flask使用中的路由系统，是通过route() 装饰器来将视图函数注册为路由。进入route函数</p><pre><code>def route(self, rule, **options):    def decorator(f):        endpoint = options.pop(&quot;endpoint&quot;, None)        self.add_url_rule(rule, endpoint, f, **options)        return f    return decorator</code></pre><p>可见内部调用了add_url_rule，并将函数作为参数传入。看到add_url_rule存在关键的语句</p><pre><code># url_map实际上就是Map类的实例# rule就是通过route相关更正成的Rule实例self.url_map.add(rule)# view_functions是一个字典，存储了端点和视图函数的映射关系。可用于查询self.view_functions[endpoint] = view_func</code></pre><p>再进入底层就会发现，实际上就同上例的werkzeug实现</p><h1 id="导入config配置参数"><a href="#导入config配置参数" class="headerlink" title="导入config配置参数"></a>导入config配置参数</h1><p>最初，我们修改配置文件会使用以下方法</p><pre><code>app.config[&apos;DEGUB&apos;] = True</code></pre><p>导入参数</p><pre><code>import configapp.config.from_object(config)# 在config.py 文件中 存放配置参数DEBUG = TrueSECRET_KEY = os.urandom(24)DIALECT = &apos;mysql&apos;DRIVER = &apos;mysqlconnector&apos;USERNAME = &apos;root&apos;PASSWORD = &apos;root&apos;HOST = &apos;127.0.0.1&apos;PORT = &apos;3306&apos;DATABASE = &apos;test&apos;</code></pre><p>如果自定义了配置文件类也可传入字符串</p><pre><code>app.config.from_object(&apos;config.Foo&apos;)# 以上代表 config.py文件中的 Foo类</code></pre><p>进入from_object() 函数 [位于config.py]</p><pre><code>def from_object(self, obj):    if isinstance(obj, string_types):        obj = import_string(obj)    for key in dir(obj):        if key.isupper():            self[key] = getattr(obj, key)</code></pre><p>首先判断如果是字符串类型的，做相应处理获得对象。在import_string函数中</p><pre><code>module_name, obj_name = import_name.rsplit(&quot;.&quot;, 1)module = __import__(module_name, globals(), locals(), [obj_name])</code></pre><p>dir()函数的作用：</p><pre><code>dir() 函数不带参数时，返回当前范围内的变量、方法和定义的类型列表；带参数时，返回参数的属性、方法列表。如果参数包含方法__dir__()，该方法将被调用。如果参数不包含__dir__()，该方法将最大限度地收集参数信息。</code></pre><p>获取属性后判断是否为<strong>大写</strong>，是则添加为配置参数</p><h2 id="用类导入配置的作用"><a href="#用类导入配置的作用" class="headerlink" title="用类导入配置的作用"></a>用类导入配置的作用</h2><p>在开发和线上，往往采用的不是相同的配置文件。我们可以通过类封装几套配置文件以供使用。</p><p>可以编写一个基础类，在开发测试、线上运行都相同、都需要的配置参数。再通过继承，扩展不同环境下的不同配置参数。</p><p>则在不同的环境下，只需要改变from_object() 中的参数即可。</p><h1 id="Flask如何处理请求"><a href="#Flask如何处理请求" class="headerlink" title="Flask如何处理请求"></a>Flask如何处理请求</h1><h2 id="app程序对象"><a href="#app程序对象" class="headerlink" title="app程序对象"></a>app程序对象</h2><p>在一些Python web框架中，视图函数类似</p><pre><code>@route(&apos;/&apos;)def index():    return &apos;hello&apos;</code></pre><p>但在flask中</p><pre><code>@app.route(&apos;/&apos;)def index():    return &apos;hello&apos;</code></pre><p>flask 中存在一个显式的程序对象，我们需要在全局空间中创建它。设计原因主要包括：</p><ul><li>相较于隐式程序对象，同一时间只能有一个实例存在，显式的程序对象允许多个程序实例存在。</li><li>允许通过子类化Flask类来改变程序行为。</li><li>允许通过工厂函数来创建程序实例，可以在不同的地方传入不同的配置来创建不同的程序实例。</li><li>允许通过蓝本来模块化程序。</li></ul><h2 id="启动app-run"><a href="#启动app-run" class="headerlink" title="启动app.run()"></a>启动app.run()</h2><p>在Flask类中</p><p>当调用app.run()，程序启动。我们查看run()函数的源码</p><pre><code>from werkzeug.serving import run_simpletry:    run_simple(host, port, self, **options)finally:    # reset the first request information if the development server    # reset normally.  This makes it possible to restart the server    # without reloader and that stuff from an interactive shell.    self._got_first_request = False</code></pre><p>可见run_simple函数，而第三个参数是self，即flask对象。</p><p>当调用对象时，python会执行<code>__call__</code>方法。</p><p>进入Flask() 类可以看到</p><pre><code>    def wsgi_app(self, environ, start_response):        ctx = self.request_context(environ)        error = None        try:            try:                ctx.push()                response = self.full_dispatch_request()            except Exception as e:                error = e                response = self.handle_exception(e)            except:  # noqa: B001                error = sys.exc_info()[1]                raise            return response(environ, start_response)        finally:            if self.should_ignore_error(error):                error = None            ctx.auto_pop(error)def __call__(self, environ, start_response):    &quot;&quot;&quot;The WSGI server calls the Flask application object as the    WSGI application. This calls :meth:`wsgi_app` which can be    wrapped to applying middleware.&quot;&quot;&quot;    return self.wsgi_app(environ, start_response)</code></pre><p>当请求到来时，程序在调用app时，由于实现了<code>__call__</code>函数，则通过该函数调用了wsgi_app()函数</p><p>具体分析wsgi_app函数：</p><ol><li>生成request请求对象和请求上下文（封装在request_context函数里）</li><li>将生成的请求上下文（本次请求的环境）push入栈，存储。</li><li>请求进入预处理（例如before_request），错误处理及请求转发到响应的过程（full_dispatch_request函数）</li></ol><p>详情查看：</p><blockquote><p><a href="https://blog.csdn.net/bestallen/article/details/54342120" target="_blank" rel="noopener">https://blog.csdn.net/bestallen/article/details/54342120</a></p></blockquote><h3 id="before-request-after-request"><a href="#before-request-after-request" class="headerlink" title="before_request\after_request"></a>before_request\after_request</h3><p>在平常使用中，我们还会使用装饰器before_request对某些请求执行前做一些相关操作。</p><p>我们进入before_request源码中，可以看到实际上就一行代码</p><pre><code>def before_request(self, f):    self.before_request_funcs.setdefault(None, []).append(f)    return f</code></pre><p>并且从源码中可以看到before_request_funcs只是Flask类中初始化的一个空字典。所以以上函数就是将字典设置为</p><pre><code>{    None : [func1, func2...]    }</code></pre><p>键为none，值为存储了before_request函数的列表</p><p>回头再看到当请求到达时，<code>__call__</code>调用wsgi_aqq函数</p><pre><code># 先是将请求相关的资源环境封装成请求上下文对象 并入栈ctx = self.request_context(environ)error = Nonetry:    try:        ctx.push()        response = self.full_dispatch_request()</code></pre><p>进入full_dispatch_request</p><pre><code>try:    request_started.send(self)    rv = self.preprocess_request()    if rv is None:        rv = self.dispatch_request()</code></pre><p>再进入preprocess_request</p><pre><code>bp = _request_ctx_stack.top.request.blueprintfuncs = self.url_value_preprocessors.get(None, ())if bp is not None and bp in self.url_value_preprocessors:    funcs = chain(funcs, self.url_value_preprocessors[bp])for func in funcs:    func(request.endpoint, request.view_args)funcs = self.before_request_funcs.get(None, ())if bp is not None and bp in self.before_request_funcs:    funcs = chain(funcs, self.before_request_funcs[bp])for func in funcs:    rv = func()    if rv is not None:        return rv</code></pre><p>看到后半部分，实际上就是把刚刚字典（before_request_funcs）中的的函数遍历出来执行。如果存在返回值，则直接返回。</p><p>所有如果当前的before_request函数存在并且返回了值，则之后的函数before_request函数后不会被执行，并且视图函数也不会执行，可见调用before_request的源码（前文已提到）</p><pre><code>rv = self.preprocess_request()# 若不存在返回值， 才执行视图函数 if rv is None:    rv = self.dispatch_request()# 否则处理错误except Exception as e:    rv = self.handle_user_exception(e)# 执行后处理 生成最终的responsereturn self.finalize_request(rv)</code></pre><p>再看一下finalize_request</p><pre><code>def finalize_request(self, rv, from_error_handler=False):&apos;&apos;&apos;把视图函数返回值转换为响应，然后调用后处理函数&apos;&apos;&apos;    response = self.make_response(rv)   # 生成响应       try:        response = self.process_response(response)  # 响应预处理        request_finished.send(self, response=response)  # 发送信号    except Exception:        if not from_error_handler:            raise        self.logger.exception(            &quot;Request finalizing failed with an error while handling an error&quot;        )    return response</code></pre><p>所以总结流程就是：</p><ol><li>preprocess_request函数执行预处理（例before_request）</li><li>若相关预处理函数出现返回值，提前结束</li><li>若正常执行完所有预处理函数，无返回值</li><li>调用dispatch_request，执行视图函数，将结果封装成rv</li><li>将视图函数生成的返回值rv传递给finalize_request，生成响应对象并且执行后处理</li></ol><h3 id="整理flask请求进入的逻辑"><a href="#整理flask请求进入的逻辑" class="headerlink" title="整理flask请求进入的逻辑"></a>整理flask请求进入的逻辑</h3><pre><code>wsgi ( run_simple函数等待请求到来)        ↓调用flask的 __call__ ( 由于run_simple的self参数)        ↓__call__ 返回调用 wsgi_app()            →           ctx = self.request_context(environ) 把请求相关信息传入初始化得一个ctx对象(请求上下文)                ctx.push() 将上下文对象入栈(localStack) → Local存储(维护__storage__ = {122:{stack:[ctx,]}})        ↓视图函数从localStack(再从local)中取出上下文进行操作</code></pre><p><img src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=3490576137,4161798228&fm=26&gp=0.jpg" alt="image"></p><h3 id="关于Local"><a href="#关于Local" class="headerlink" title="关于Local"></a>关于Local</h3><p>通过上述关系，可知local是作为一个动态的存储仓库。通过线程/进程id设置其运行环境（上下文）。</p><p>进入Local()类中 【local.py】</p><pre><code>class Local(object):    __slots__ = (&quot;__storage__&quot;, &quot;__ident_func__&quot;)    def __init__(self):        object.__setattr__(self, &quot;__storage__&quot;, {})        object.__setattr__(self, &quot;__ident_func__&quot;, get_ident)    def __getattr__(self, name):        try:            return self.__storage__[self.__ident_func__()][name]        except KeyError:            raise AttributeError(name)    def __setattr__(self, name, value):        ident = self.__ident_func__()        storage = self.__storage__        try:            storage[ident][name] = value        except KeyError:            storage[ident] = {name: value}</code></pre><p>可以看到init函数中 调用了object类的setattr。但实际上本类中也存在，甚至可以不使用setattr，直接用赋值语句 <code>__storage__</code> = {}也可。那为什么要调用父类的setattr呢。</p><pre><code>回到Local的作用：动态的存储运行环境。Local采用__storage__作为仓库存储那么面临两个问题：1. 初始化__storage__2. 动态赋值（格式为__storage__ :{122:{stack:[ctx,]}}）解决动态赋值问题，即重写赋值函数（赋值语句的实质就是调用__setattr__）从源码中可以看到Local类重写了__setattr__函数，实现了所需的要求那么此时该如何初始化__storage__呢由于我们新重写的setattr函数中调用了storage，但未初始化之前就使用了它，明显错误于是使用object的setattr函数来初始化storage，就完美的解决了以上问题。</code></pre><h3 id="关于LocalStack"><a href="#关于LocalStack" class="headerlink" title="关于LocalStack"></a>关于LocalStack</h3><p>注：在local中 <code>__storage__</code>的实质是字典，它的val也是字典(不同进程线程的存储空间)，val的key名为stack（源码规定）， val的val是列表(用栈实现)（用于管理上下文）</p><p>在单次请求中，我们真正要使用的是当前环境下的上下文，所以如果只依靠Local：</p><pre><code>obj = Local()obj.stack = []obj.stack.append(上下文环境)</code></pre><p>显然不易于维护、可扩展性差</p><p>于是使用LocalStack作为代理。查看源码LocalStack()类 （<code>local.py</code>）</p><pre><code>class LocalStack(object):    def __init__(self):        self._local = Local()    def push(self, obj):        &quot;&quot;&quot;Pushes a new item to the stack&quot;&quot;&quot;        rv = getattr(self._local, &quot;stack&quot;, None)        if rv is None:            self._local.stack = rv = []        rv.append(obj)        return rv    def pop(self):        &quot;&quot;&quot;Removes the topmost item from the stack, will return the        old value or `None` if the stack was already empty.        &quot;&quot;&quot;        stack = getattr(self._local, &quot;stack&quot;, None)        if stack is None:            return None        elif len(stack) == 1:            release_local(self._local)            return stack[-1]        else:            return stack.pop()    @property    def top(self):        try:            return self._local.stack[-1]        except (AttributeError, IndexError):            return None</code></pre><p>由源码可见</p><ol><li>LocalStack在init中创建了一个Local对象，此时storage是一个空字典</li><li>当调用push时，即传入线程或进程对象时，先判断是否已存在，否则新创建一个空间（列表，作为栈），入栈</li><li>当调用top时，返回栈顶元素</li><li>调用pop时若栈中只剩一个元素，则取出后删除该栈空间，否则pop栈顶元素</li></ol><h4 id="在上下文之前"><a href="#在上下文之前" class="headerlink" title="在上下文之前"></a>在上下文之前</h4><p>在解释上下文之前，先看看上下文和以上的栈有什么联系</p><p>通过以上实现的栈，我们做出以下假设，用上下文存储当前请求的环境(包括request信息、session等)</p><pre><code># 请求上下文class RequestContext(object):    def __init__(self):        self.request = &quot;xx&quot;        self.session = &quot;oo&quot;# 初始化一个存储栈空间xxx = LocalStack()# 当请求进入时，初始化一个请求上下文、封装了当前环境ctx = RequestContext()# 将该请求上下文入栈xxx.push(ctx)# 当需要使用相关资源时，取当前栈顶元素，即可操作相关数据obj = xxx.top()obj.requestobj.session</code></pre><p>具体源码下章解析</p><h1 id="本地上下文"><a href="#本地上下文" class="headerlink" title="本地上下文"></a>本地上下文</h1><p>以上所谈及的上下文究竟是什么呢？</p><p>在多线程环境下，要想让所有视图函数都获取请求对象。</p><ul><li>最直接的方法就是在调用视图函数时将所有需要的数据作为参数传递进去，但这样一来程序逻辑就变得冗余不易于维护。</li><li>另一种方法是将这些数据设为全局变量，但是这样必然会在不同的线程中出现混乱（非线程安全）。<br>本地线程（thread locals） 的出现解决了这些问题。</li></ul><p>本地线程就是一个全局对象，使用一种<strong>特定线程且线程安全</strong>的方式来存储和获取数据。也就是说，<strong>同一个变量在不同线程内拥有各自的值，互不干扰。</strong></p><p>实现原理其实很简单，就是根据线程的ID来存取数据。</p><blockquote><p>Flask没有使用标准库的threading.local()，而是使用了Werkzeug自己实现的本地线程对象werkzeug.local.Local()，后者增加了对Greenlet（以C扩展形式接入python的轻量级协程）的优先支持。</p></blockquote><p>Flask使用本地线程来让上下文代理对象全局可访问，比如：</p><ul><li>request</li><li>session</li><li>current_app</li><li>g</li></ul><p>这些对象被称为本地上下文对象（context locals）。</p><p>所以，在不基于线程、greenlet或单进程实现的并发服务器上，这些代理对象将无法正常工作，但仅有少部分服务器不支持。</p><blockquote><p>Flask的设计初衷是为了让传统Web程序开发更加简单和迅速，二不是用来开发大型程序或异步服务器的。但Flask 的可扩展性却提供了无限的可能性，除了使用扩展，还可以子类化Flask类或为程序添加中间件。</p></blockquote><p>应用上下文、请求上下文都是对象，是对一系列flask对象的封装，并且提供相关的接口方法。</p><ul><li>请求上下文： request session</li><li>应用上下文： app      g</li><li>flask中上下文相关的代码存放在 <code>ctx.py</code></li></ul><h2 id="请求上下文"><a href="#请求上下文" class="headerlink" title="请求上下文"></a>请求上下文</h2><p>请求上下文最主要的是提供对Request请求对象的封装。</p><pre><code>RequestContext(object)  // 请求上下文    - __init__    - push    - pop    - __enter__    - __exit__</code></pre><p>先看源码中init函数的作用</p><pre><code>def __init__(self, app, environ, request=None, session=None):    self.app = app    if request is None:        request = app.request_class(environ)    self.request = request    self.url_adapter = None    try:        self.url_adapter = app.create_url_adapter(self.request)    except HTTPException as e:        self.request.routing_exception = e    self.flashes = None    self.session = session</code></pre><p>可以看到就是对当前请求相关数据的初始化，如 当前app对象、request、session、flashes等，符合上章所提到的上下文和栈的关系作用。</p><h3 id="认识"><a href="#认识" class="headerlink" title="认识"></a>认识</h3><p>请求到来时：</p><pre><code># self是app对象，environ是请求相关的原始数据(根据WSGI规定)ctx = RequestContext(self, environ)ctx.request = Request(environ)ctx.session = None# 不同的线程在内部分别持有不同的资源{    1232：{ctx: ctx对象}    1231：{ctx: ctx对象}    2141：{ctx: ctx对象}    1235：{ctx: ctx对象}}</code></pre><p>视图函数：</p><pre><code>from flask import request,session# falsk 自动的识别当前线程，找到对应的ctx里的request、session</code></pre><p>请求结束：</p><pre><code>根据当前线程的唯一标记，将数据资源移除</code></pre><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>flask利用local()为线程或协程开辟资源空间，并用stack【栈】存储维护，内部再使用偏函数【functools.partial(func1, 10)】拆分各属性值。</p><pre><code>    app.run()0. wsgi(处理请求，准备调用__call__)1. app.__call__(准备调用wsgi_app)2. app.wsgi_app(准备实例化RequestContext)3. ctx = RequestContext(session, request)    - 请求相关+空session 封装到RequestContext（ctx） 4. ctx.push()    - 将ctx交给LocalStack对象5. LocalStack,把ctx对象添加到local中    - LocalStack相当于将单个线程或协程的数据资源分割开来，并作为栈进行维护6. Local __storage__ = {    1231: {stack: [ctx(request, session), ]}                        }    - local的结构。存储了多个线程或协程的资源数据7. session存储    根据请求中的cookie提取名为sessionid对应的值，对cookie加密+反序列化，再赋值给ctx里的session8. 视图函数    - 利用flask已经封装好的库，调用session或request的相关资源9. 操作结束后    把session中的数据再次写入cookie中，将ctx删除10. 结果返回给用户浏览器11. 断开socket连接</code></pre><h3 id="request哪来的"><a href="#request哪来的" class="headerlink" title="request哪来的"></a>request哪来的</h3><ol><li>首先当请求进入时，<code>__call__</code>调用wsgi_app</li><li>在wsgi_app中初始化了一个请求上下文 ctx = self.request_context(environ)</li><li>可见是将environ作为参数传入，而在WSGI中规定 environ即保存着请求相关的数据</li><li>进入request_context() 函数 发现只有一行代码 return RequestContext(self, environ)</li><li>进入RequestContext类 看到init函数中 request = app.request_class(environ)</li><li>通过以上 封装了一个request对象.提供我们可以使用 request.method request.args等操作</li></ol><h3 id="session相关原理"><a href="#session相关原理" class="headerlink" title="session相关原理"></a>session相关原理</h3><p>通过源码可以看到session的继承中，存在dict。则session具备dict的所有操作。</p><pre><code>class SecureCookieSession(CallbackDict, SessionMixin):                ↓class CallbackDict(UpdateDictMixin, dict):</code></pre><ol><li>session数据保存到redis</li><li>生成一个随机字符串</li><li>返回一个随机字符串给用户，并作为key</li><li>客户端再访问时返回该随机字符串</li></ol><h4 id="flash"><a href="#flash" class="headerlink" title="flash"></a>flash</h4><p>flask中存在消息闪现机制，通过flash()源码（helpers.py）可以看到，本质上是利用session实现的</p><pre><code># category表示消息的类别，可以按类别存入，按类别弹出def flash(message, category=&quot;message&quot;):    flashes = session.get(&quot;_flashes&quot;, [])    flashes.append((category, message))    session[&quot;_flashes&quot;] = flashes    message_flashed.send(        current_app._get_current_object(), message=message, category=category    )</code></pre><p>弹出flash信息函数</p><pre><code>def get_flashed_messages(with_categories=False, category_filter=()):    flashes = _request_ctx_stack.top.flashes    if flashes is None:        _request_ctx_stack.top.flashes = flashes = (            session.pop(&quot;_flashes&quot;) if &quot;_flashes&quot; in session else []        )    if category_filter:        flashes = list(filter(lambda f: f[0] in category_filter, flashes))    if not with_categories:        return [x[1] for x in flashes]    return flashes</code></pre><p>则最终实现的效果是 flash() 存入信息，get_flashed_messages()只能对应的弹出一次。</p><h2 id="应用上下文"><a href="#应用上下文" class="headerlink" title="应用上下文"></a>应用上下文</h2><p>应用上下文最主要的就是提供对核心对象flask的封装。</p><p>源代码中类的主要结构为：</p><pre><code>AppContext(object)      // 应用上下文    - push    - pop    - __enter__    - __exit__</code></pre><h3 id="g"><a href="#g" class="headerlink" title="g"></a>g</h3><p>每个请求进入时，都会创建一个g，一次完整请求为一个生命周期。</p><p>当多线程进入时，由于g的唯一标识为线程（Local中的<code>__storage__</code>），所以资源互不影响。可以使用g为每次请求设置一个值。</p><pre><code># 例：@app.before_requestdef x1():    g.x1 = 123@app.route(&apos;/index&apos;)def index():    print(g.x1)    return &quot;index&quot;</code></pre><h3 id="current-app"><a href="#current-app" class="headerlink" title="current_app"></a>current_app</h3><h2 id="上下文与栈"><a href="#上下文与栈" class="headerlink" title="上下文与栈"></a>上下文与栈</h2><h3 id="栈到底是怎么工作的"><a href="#栈到底是怎么工作的" class="headerlink" title="栈到底是怎么工作的"></a>栈到底是怎么工作的</h3><p><img src="https://images2018.cnblogs.com/blog/1426593/201807/1426593-20180714110358443-1991593952.png" alt="image"><br>主要通过栈实现，即当一个请求进入时：</p><ol><li>实例化一个requestcontext，封装了本次请求的相关信息（在Request中）</li><li>在请求上下文入栈之前，先检查应用上下文栈（源码可见栈名为：_app_ctx_stack）是否为空，为空则将当前app push()入栈</li><li>将请求上下文push()入栈（源码可见栈名为：_request_ctx_stack）</li></ol><pre><code># RequestContext类中# 可以看到先判断app_ctx是否存在，然后再push入栈request_ctxapp_ctx = _app_ctx_stack.topif app_ctx is None or app_ctx.app != self.app:    # app_context 用于创建app_ctx对象    app_ctx = self.app.app_context()    app_ctx.push()    self._implicit_app_ctx_stack.append(app_ctx)else:    self._implicit_app_ctx_stack.append(None)_request_ctx_stack.push(self)</code></pre><p>由于以上判断，所以我们在视图函数中使用current_app时，由于有请求上下文，所以不需要手动将应用上下文app_ctx入栈。如果在视图函数外，没有请求发生时，使用current_app则需要手动入栈</p><pre><code>app_ctx = app.app_context()app_ctx.push()# 可使用current_appapp_ctx.pop()</code></pre><p>何时会用到？</p><pre><code>在实际生产中，current_app对象一般都是至与视图函数中使用由于有正在的请求到来，所以不需要手动入栈。但是在代码测试阶段，在进行单元测试时，或离线应用（不使用postman等工具发生完整请求）没有实际的请求到来，又需要对代码进行测试则需要手动将app_ctx入栈</code></pre><h4 id="with优化出入栈"><a href="#with优化出入栈" class="headerlink" title="with优化出入栈"></a>with优化出入栈</h4><pre><code># with优化 不需要手动push popwith app.app_context():         # __enter__(连接)     a = current_app         d = current_app.config[&apos;DEBUG&apos;]    #  __exit__(释放连接【资源】)    # (__exit__内部实现了异常处理，若成功处理了返回True，若没有成功处理，返回False还会向外部抛出异常)# 出了with环境 app对象被pop()出栈 current_app 就找不到目标了</code></pre><p>​<br>​    # with可以对实现了上下文协议的对象使用<br>​    # 上下文管理器(app context)<br>​    # 实现了<strong>enter</strong>(连接)  <strong>exit</strong>(释放连接【资源】)就是上下文管理器<br>​    # 上下文表达式必须要返回一个上下文管理器</p><p>​<br>​    # 此时a是<strong>enter</strong> 的返回值<br>​    with app.app_context() as a:<br>​        pass</p><p>​<br>​<br>​    # 可以自己实现上下文管理器，必须实现<strong>enter</strong> <strong>exit</strong>方法<br>​    class MyResource:<br>​<br>​        def <strong>enter</strong>(self):<br>​            print(‘connect to resource’)<br>​            # 将管理器返回再利用管理器进行相关操作<br>​            return self<br>​<br>​        def <strong>exit</strong>(self,exc_type, exc_value, tb):<br>​            print(‘close connection’)<br>​            return True/False<br>​            # 返回True 表明此若产生异常内部进行处理，外部不会接收到异常<br>​<br>        def query(self):<br>            print(‘doing’)</p><pre><code>    with MyResource() as r:        r.query()# 也可以通过装饰器,省略__enter__ __exit__ (不推荐)from contextlib import contextmanagerclass MyResource:    def query(self):        print(&apos;doing&apos;)@contextmanagerdef make_myresource():    print(&apos;connect to resource&apos;)    # yield做返回，使用结束后再回到函数关闭连接    yield MyResource()    print(&apos;close connection&apos;)with MyResource() as r:        r.query()# 但是更好的做法是将本身不是上下文管理器的类，变为上下文管理器# 例：输入书名 with中自动添加 《》 #     操作数据库 with中自动连接、回滚、断开</code></pre><h4 id="源码中的体现"><a href="#源码中的体现" class="headerlink" title="源码中的体现"></a>源码中的体现</h4><p>从源码中可以看到无论是应用上下文还是请求上下文，都具有以下两个函数</p><pre><code>def __enter__(self):    self.push()    return selfdef __exit__(self, exc_type, exc_value, tb):    # do not pop the request stack if we are in debug mode and an    # exception happened.  This will allow the debugger to still    # access the request object in the interactive shell.  Furthermore    # the context can be force kept alive for the test client.    # See flask.testing for how this works.    self.auto_pop(exc_value)    if BROKEN_PYPY_CTXMGR_EXIT and exc_type is not None:        reraise(exc_type, exc_value, tb)</code></pre><p>即在进入时将上下文入栈，使用完毕后自动pop出栈</p><h3 id="栈中的元素"><a href="#栈中的元素" class="headerlink" title="栈中的元素"></a>栈中的元素</h3><p>从源码中可以看到，push()的是上下文对象，但是我们真正使用的并非是上下文，而是current_app\request 等对象</p><p>源码中</p><pre><code>current_app = LocalProxy(_find_app)</code></pre><p>再看_find_app</p><pre><code>def _find_app():    top = _app_ctx_stack.top    if top is None:        raise RuntimeError(_app_ctx_err_msg)    return top.app</code></pre><p>注意到current_app是取app_ctx_stack的栈顶元素的app对象</p><p>同理request、g、session</p><pre><code>def _lookup_req_object(name):    top = _request_ctx_stack.top    if top is None:        raise RuntimeError(_request_ctx_err_msg)    return getattr(top, name)</code></pre><h1 id="LocalProxy代理"><a href="#LocalProxy代理" class="headerlink" title="LocalProxy代理"></a>LocalProxy代理</h1><h2 id="代理有什么用？"><a href="#代理有什么用？" class="headerlink" title="代理有什么用？"></a>代理有什么用？</h2><p>所有的数据都存储在Local中，如果直接对数据进行存取，需要建立多个类进行对数据的存取。如request类、session类、g类、current_app类。</p><p>但是由于以上类的功能相同，可以抽象出来，使用一个代理类，完成所需功能。</p><h2 id="知识预备"><a href="#知识预备" class="headerlink" title="知识预备"></a>知识预备</h2><pre><code># 偏函数import functoolsdef index(a1, a2)    return a1 + a2new_func = functools.partial(index, 666)# 帮助自动传递参数new_func(1)     // 667</code></pre><h3 id="源码体现"><a href="#源码体现" class="headerlink" title="源码体现"></a>源码体现</h3><p>在我们实际运用中，并不是直接去操作上下文。而是使用例如：current_app\request\session\g等 通过源码看到</p><pre><code>_request_ctx_stack = LocalStack()_app_ctx_stack = LocalStack()current_app = LocalProxy(_find_app)request = LocalProxy(partial(_lookup_req_object, &quot;request&quot;))session = LocalProxy(partial(_lookup_req_object, &quot;session&quot;))g = LocalProxy(partial(_lookup_app_object, &quot;g&quot;))</code></pre><p>我们先进入LocalProxy类，看到init函数</p><pre><code>def __init__(self, local, name=None):    object.__setattr__(self, &quot;_LocalProxy__local&quot;, local)    object.__setattr__(self, &quot;__name__&quot;, name)    if callable(local) and not hasattr(local, &quot;__release_local__&quot;):        # &quot;local&quot; is a callable that is not an instance of Local or        # LocalManager: mark it as a wrapped function.        object.__setattr__(self, &quot;__wrapped__&quot;, local)</code></pre><p>即为该对象设置值，而我们在实例化的时候，传递的参数是一个偏函数</p><p>那么当我们创建完代理对象后，考虑我们是怎样使用这些代理的： request.method request.args等，则实际上会调用对象的getattr。进入源码</p><pre><code>def __getattr__(self, name):    if name == &quot;__members__&quot;:        return dir(self._get_current_object())    return getattr(self._get_current_object(), name)</code></pre><p>进入_get_current_object函数</p><pre><code>def _get_current_object(self):    &quot;&quot;&quot;Return the current object.  This is useful if you want the real    object behind the proxy at a time for performance reasons or because    you want to pass the object into a different context.    &quot;&quot;&quot;    if not hasattr(self.__local, &quot;__release_local__&quot;):        return self.__local()    try:        return getattr(self.__local, self.__name__)    except AttributeError:        raise RuntimeError(&quot;no object bound to %s&quot; % self.__name__)</code></pre><p>而local()实际上就是我们传递进来的偏函数（init()初始化的结果）</p><p>回头看一下传递进来的偏函数，看到源码中的_lookup_req_object</p><pre><code>def _lookup_req_object(name):    top = _request_ctx_stack.top    if top is None:        raise RuntimeError(_request_ctx_err_msg)    return getattr(top, name)</code></pre><p>即取出栈顶的元素(上下文)，再通过getattr获取到相关的内容。而erquest、session等，在前面也已经看到，是在上下文初始化时就创建的。所以该函数最终就是根据传递进来的参数(request, session, g, current_app)，进入到local栈中，top拿到栈顶的上下文，然后在上下文中取出所需的资源。</p><h1 id="三种程序状态"><a href="#三种程序状态" class="headerlink" title="三种程序状态"></a>三种程序状态</h1><p>Flask提供的四个本地上下文对象分别在特定的程序状态下绑定实际的对象。如果我们在访问或使用它们时还没有绑定，就会看到经典的RuntimeError异常。</p><p>Flask中存在三种状态：</p><ul><li>程序设置状态</li><li>程序运行状态</li><li>请求运行状态</li></ul><h2 id="程序设置状态"><a href="#程序设置状态" class="headerlink" title="程序设置状态"></a>程序设置状态</h2><p>当Flask类被实例化，也就是创建程序实例app后，就进入程序设置状态。这是所有的全局对象都没有被绑定：</p><pre><code>app = Flask(__name__)</code></pre><h2 id="程序运行状态"><a href="#程序运行状态" class="headerlink" title="程序运行状态"></a>程序运行状态</h2><p>当Flask程序启动，但是还没有请求进入时，Flask进入了程序运行状态。<br>在这种状态下，程序上下文对象current_app和g都绑定了各自的对象。</p><p>使用flask shell命令打开的python shell默认就是这种状态，我们也在普通的Python shell中通过手动推送程序上下文来模拟：</p><pre><code>app = Flask(__name__)ctx = app.app_context()ctx.push()# current_app g     /Flask flask.g# requst session  /unbound</code></pre><p>以上我们手动使用app_context() 创建了程序上下文，然后调用push() 方法把它推送到程序上下文堆栈里。</p><p>默认情况下，当请求进入的时候，程序上下文会随着请求上下文一起被自动激活。但是在没有请求进入的场景，比较离线脚本、测试或者进行交互调试的时候，手动推送程序上下文以进入程序运行状态会非常方便。</p><h2 id="请求运行状态"><a href="#请求运行状态" class="headerlink" title="请求运行状态"></a>请求运行状态</h2><p>当请求进入的时候，或是使用test_request_context()方法、test_client()方法时，Flask会进入请求运行状态。因为当请求上下文被推送时，程序上下文会被自动推送，所以在这个状态下4个全局对象都会被绑定。我们可以通过手动推送请求上下文模拟：</p><pre><code>app = Flask(__name__)ctx = app.test_request_context()ctx.push()# current_app, g, request, session# Flask flask.g Request NullSession</code></pre><p>这也是为什么可以直接在视图函数和相应的回调函数里直接使用这些上下文对象，而不用推送上下文（Flask在处理请求时会自动推送请求上下文和程序上下文）</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ul><li>《Flask Web 开发实战》</li><li>各类视频资料…</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;两个核心依赖&quot;&gt;&lt;a href=&quot;#两个核心依赖&quot; class=&quot;headerlink&quot; title=&quot;两个核心依赖&quot;&gt;&lt;/a&gt;两个核心依赖&lt;/h1&gt;&lt;p&gt;falsk主要依赖两个库 —— Werkzeug 和 Jinja。&lt;/p&gt;
&lt;h2 id=&quot;Jinja2&quot;&gt;
      
    
    </summary>
    
    
      <category term="Flask" scheme="https://sssmeb.github.io/tags/Flask/"/>
    
      <category term="Python" scheme="https://sssmeb.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Flask部署知识（Nginx+uWSGI+HTTPS）</title>
    <link href="https://sssmeb.github.io/2019/04/25/Flask%E9%83%A8%E7%BD%B2%E7%9F%A5%E8%AF%86%EF%BC%88Nginx-uWSGI-HTTPS%EF%BC%89/"/>
    <id>https://sssmeb.github.io/2019/04/25/Flask部署知识（Nginx-uWSGI-HTTPS）/</id>
    <published>2019-04-25T08:26:26.000Z</published>
    <updated>2019-08-15T08:52:07.699Z</updated>
    
    <content type="html"><![CDATA[<h3 id="名词解析"><a href="#名词解析" class="headerlink" title="名词解析"></a>名词解析</h3><h5 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h5><p>封装了处理HTTP响应、TCP连接等操作的接口。用户不需要自己实现接受HTTP请求、解析HTTP请求、发送HTTP响应等操作，不需要专注于HTTP规范等，可以专心编写Web业务。</p><h5 id="werkzeug"><a href="#werkzeug" class="headerlink" title="werkzeug"></a>werkzeug</h5><p>flask自带WSGI工具包，可以搭建WSGI服务。但只用于开发，实际生产需要用更专业高效的Web服务器。</p><h5 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h5><p>Web服务器。它实现了WSGI协议、uwsgi、http等协议，是一个全站式的托管服务，支持多种编程语言。</p><h5 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h5><p>高效的Web服务器和反向代理服务器，可以用于负载均衡。也支持uWSGI的uwsgi协议，所以可以将Nginx与uWSGI结合起来。</p><ul><li>相较于Apache，Nginx支持高并发，部署简单，内存消耗少。但是Apache发展更久，模块更丰富，社区更大。</li></ul><p>Nginx 以其高性能、稳定性、丰富的功能、简单的配置、低资源消耗而闻名。</p><p>Nginx 是一个可以为你的 Web 应用处理 HTTP 请求的服务器。对于典型的 Web 应用，Nginx 可以配置为 HTTP 请求进行以下操作：</p><ul><li>将请求 反向代理 至上游服务器（例如 Gunicorn、uWsgi、Apache 等）。</li><li>为静态资源（Javascript 文件、CSS 文件、图像、文档、静态 HTML 文件）提供服务。</li></ul><h6 id="uWSGI与nginx的区别"><a href="#uWSGI与nginx的区别" class="headerlink" title="uWSGI与nginx的区别"></a>uWSGI与nginx的区别</h6><p>uWSGI与Nginx同是Web服务器，但是Nginx对于处理静态文件更有优势、性能更好。表现在Nginx能进行负载均衡、HTTP缓存、高效处理高并发请求等等。所以把这两者结合起来使用，能够使服务器更稳定、高效。</p><p>在我们的模型中：</p><ul><li>nginx是对外的服务器，外部浏览器通过url访问nginx,uwsgi是对内的服务器，主要用来处理动态请求。</li><li>nginx接收到浏览器发送过来的http请求，将包进行解析，分析url， </li></ul><pre><code>a.如果是静态文件请求就直接访问用户给nginx配置的静态文件目录，直接返回用户请求的静态文件， b.如果不是静态文件，而是一个动态的请求，那么nginx就将请求转发给uWSGI。所以抽象出来    用户 →  nginx   →   uWSGI</code></pre><p>  <img src="https://upload-images.jianshu.io/upload_images/3120119-9863875b84d6ebf4.jpeg?imageMogr2/auto-orient/" alt="image"></p><blockquote><p>图片取自<a href="https://www.jianshu.com/p/85692a94e99b" target="_blank" rel="noopener">https://www.jianshu.com/p/85692a94e99b</a></p></blockquote><h5 id="uwsgi"><a href="#uwsgi" class="headerlink" title="uwsgi"></a>uwsgi</h5><p>uwsgi是一种线路协议而不是通信协议。uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型。</p><h5 id="Flask"><a href="#Flask" class="headerlink" title="Flask"></a>Flask</h5><p>为什么不直接使用Flask内置作为Web服务器</p><ul><li>高并发：flask本身不支持并发，需要uwsgi+flask开启多个worker</li><li>性能：使用这种模式，将解析http协议放到了nginx，由于nginx这样用C/C++高性能实现的服务器，比起Python脚本语言解析HTTP协议，效率要高。</li></ul><hr><h3 id="依赖安装"><a href="#依赖安装" class="headerlink" title="依赖安装"></a>依赖安装</h3><ul><li>python</li><li>nginx</li><li>uwsgi</li><li>gcc（由于uwsgi是用c编写的所以依赖c编译器）</li></ul><p>安装比较简单，不赘述。</p><p>工具主要使用Xshell和Xftp，均有官方免费版。</p><hr><h3 id="部署流程"><a href="#部署流程" class="headerlink" title="部署流程"></a>部署流程</h3><ul><li>开发：windows10 + pycharm + Flask</li><li>服务器：虚拟环境python3.6（conda管理） + centos7</li></ul><h4 id="1、项目文件上传至服务器"><a href="#1、项目文件上传至服务器" class="headerlink" title="1、项目文件上传至服务器"></a>1、项目文件上传至服务器</h4><p>比较简单，提供三种做法</p><ol><li>git管理（推荐）</li><li>Xftp工具上传至服务器</li><li>scp命令（较少用在win和linux之间）</li></ol><pre><code>常用：    scp /cloud/data/test.txt root@10.21.156.6:/cloud/data/</code></pre><h4 id="uwsgi-1"><a href="#uwsgi-1" class="headerlink" title="uwsgi"></a>uwsgi</h4><p>如果是简单项目、参数较少或者是测试 可以直接在命令行传递参数，启动项目</p><pre><code>uwsgi --wsgi-file app.py --processes 4 --threads 2</code></pre><p>当然，正常项目都是使用配置文件，可以更方便的修改、管理众多的参数。所以在项目目录下创建一个uwsgi.ini文件进行配置。</p><p>接下来记录一下主要使用到的一些参数以及参数配置时要注意的问题</p><pre><code># 如果是使用虚拟环境运行的，要配置虚拟环境地址    home = /ENV</code></pre><p>​<br>​    # 项目根目录<br>​    chdir = /项目地址<br>​    # app所在的启动文件<br>​    wsgi-file = /项目地址/app.py<br>​    # flask特需的参数，指明app对象名称<br>​    callable = hello</p><p>​<br>​<br>​    # 最大进程数，推荐匹配cpu数<br>​    processes = 4<br>​    # 每个进程开启的线程数<br>​    threads = 2<br>​<br>​    # socket方式与nginx连接，此参数需要对应nginx参数。即同步连接通道。<br>​    socket = 127.0.0.1:5001<br>​    # 为socket操作文件赋予权限<br>​    chmod-socket = 666</p><p>​<br>​    # 环境退出时自动清理，包含pid、sock和status文件<br>​    vacuum = true<br>​    # 日志路径<br>​    logto = /tmp/uwsgi/uwsgi.log</p><p>让supervisor管理uwsgi，可以在uwsgi发生意外的情况下，会自动的重启。本次没有使用，先做下记录。</p><h5 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h5><pre><code>uwsgi --ini /etc/uwsgi_config.ini       #初始化uwsgi服务uwsgi --stop /etc/uwsgi_config.ini      #停止uwsgi服务uwsgi --reload /etc/uwsgi_config.ini    #重新加载uwsgi服务##重启命令可能无效,请尝试先杀死相关进程然后再重启killall -9 nginx                        #kill所有 nginx相关进程killall -9 uwsgi                        #kill所有 uwsgi 相关进程</code></pre><h4 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h4><h5 id="nginx常见操作"><a href="#nginx常见操作" class="headerlink" title="nginx常见操作"></a>nginx常见操作</h5><blockquote><p>如果不知道nginx启动文件在哪可以使用 whereis nginx</p></blockquote><pre><code># 启动/usr/local/nginx/sbin/nginxcd /usr/local/nginx/sbin# 判断配置文件是否正确./nginx -t# 关闭./nginx -s quit         # 完成已接受的连接请求，正常停止./nginx -s stop         # 直接关闭，快速停止# 当然也可以杀死进程ps -ef | grep nginxkill -quit 进程id# 当配置文件错乱是 可-c指定该文件作为配置文件nginx -c ./nginx.conf# 平滑重启 不停止nginx的情况下，重新加载配置文件./nginx -s reload</code></pre><p>​<br>​    # 当端口重复占用时，可能是nginx服务卡死，可以先杀死，再重启<br>​    # 查看正在监听的端口<br>​    netstat -ntpl<br>​    kill xx</p><h5 id="普通配置"><a href="#普通配置" class="headerlink" title="普通配置"></a>普通配置</h5><pre><code>备份原有的nginx文件（备份是一个良好的习惯，再修改配置文件的时候最好都要备份一下）cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak</code></pre><p>Nginx的顶层配置是nginx.conf。Nginx接受多层级的配置文件，这也使得用户可以针对自己的应用进行弹性的配置。</p><hr><p>在Nginx中，由配置块来组织各个配置参数。</p><ul><li>Main – 定义于 nginx.conf（所有不属于配置块的参数均属 Main 块）</li><li>Events – 定义于 nginx.conf</li><li>Http – 定义于 nginx.conf</li><li>Server – 定义于 application_name.conf</li></ul><p>nginx默认安装的配置文件在/etc/nginx/nginx.conf </p><p>以下基础配置（缺省了一些不常用、默认参数）</p><pre><code># Nginx服务器的拥有者以及运行用户user root;# 进程数，推荐匹配服务器cpu核数worker_processes  1;# 错误日志error_log /tmp/nginx/nginx.log;# 定义pid的文件 默认pid /run/nginx.pid;# 定义了处理连接相关的参数events {    # 最大并发连接数    worker_connections  1024;}http {</code></pre><p>​<br>​        # 添加此文件下.conf的配置文件<br>​        include /etc/nginx/conf.d/*.conf;<br>​        # 默认返回给用户的文件类型。<br>​        # 对于我们Flask应用来说，应该是动态生成的HTML文件 text/html;<br>​        default_type  application/octet-stream;<br>​<br>​        # 关于日志的参数保持默认<br>​<br>​        # 开启高效传输模式<br>​        sendfile            on;<br>​        # 减少网络报文段的数量<br>​        tcp_nopush          on;<br>​        tcp_nodelay         on;<br>​        # 保持连接的时间<br>​        keepalive_timeout   65;<br>​        # 最大块<br>​        types_hash_max_size 2048;</p><p>​<br>​        server {<br>​            listen 80;                                          # 监听ipv4<br>​            listen       [::]:80 ipv6only=on default_server;    # 监听ipv6<br>​            # listen [::]:80    可同时监听ipv4、ipv6 若出错则采用上述方法<br>​            server_name xxx.com;                                 # 可写域名或者ip地址<br>​<br>​            # 定义了在请求未指定页面时所得到的默认页面。<br>​            # 这里我们是使用FlaskWeb应用生成，因此注释掉<br>​            # index index.html;<br>​<br>​            # /指访问路径，可加前缀 例：/test 则在此location下url都需要添加前缀<br>​            location / {<br>​                include uwsgi_params;<br>​                # 关键！当uwsgi和nginx使用socket连接时，连接通道。必须和uwsgi文件里的socke参数一致<br>​                uwsgi_pass 127.0.0.1:5001;</p><p>​<br>​                # 访问静态资源时。在flask中可以将静态资源（如图片）放至staic供前端调用显示<br>​                root /项目地址;<br>​                # alias /项目地址<br>​                # root和alias是对应的 都是指定当url请求时查找服务器资源的路径<br>​                # alias 会将location的访问路径缺省再搜索服务器<br>​<br>​            }<br>​    }</p><blockquote><p>每行配置记得加 ; python写习惯了容易忘</p></blockquote><p>当监听多个端口时则多加一个server。不能在同一个服务里监听多个端口。</p><p>另一个server使用443，配置https服务</p><h5 id="https配置"><a href="#https配置" class="headerlink" title="https配置"></a>https配置</h5><blockquote><p>此处只将相关配置，SSL证书、域名等获取方法请走百度</p></blockquote><p>https可以通过uwsgi配置，也可以通过nginx配置。</p><p>按我们的模型逻辑，我们在nginx配置。首先申请SSL证书，然后下载相关文件获取到公钥密钥。_XXX.com_bundle.crt/2_XXX.com.key文件。上传至服务器（scp、xftp等方法都行），最好限制一下文件的读写权限。</p><p>以下至列举出不同于http的配置参数。</p><pre><code>server_name  www.example.com;server {    # https默认是443端口    listen       443 ssl http2 default_server;    listen       [::]:443 ssl http2 default_server;    # 公钥    ssl_certificate /etc/nginx/1_xx.cn_bundle.crt;    # 私钥    ssl_certificate_key /etc/nginx/2_xx.cn.key;</code></pre><p>​<br>​        # 会话缓存，并使缓存可以在机器间共享。1m大概包含4000个会话<br>​        # 简化握手阶段<br>​        ssl_session_cache shared:SSL:1m;<br>​        # 客户端可以重用会话缓存中ssl参数的过期时间。可以按需要增长。min<br>​        # 可减少多次握手运算占用CPU资源<br>​        ssl_session_timeout  10m;<br>​<br>​        # 指定SSL服务器端支持的协议版本<br>​        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;<br>​        # 加密套件<br>​        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;<br>​        # 有限服务器的加密套件<br>​        ssl_prefer_server_ciphers on;</p><p>补一下私钥文件的相关信息</p><pre><code>CSR：Cerificate Signing Request，证书签署请求文件，里面包含申请者的 DN（Distinguished Name，标识名）和公钥信息，在第三方证书颁发机构签署证书的时候需要提供。证书颁发机构拿到 CSR 后使用其根证书私钥对证书进行加密并生成 CRT 证书文件，里面包含证书加密信息以及申请者的 DN 及公钥信息。Key：证书申请者私钥文件，和证书里面的公钥配对使用，在 HTTPS 『握手』通讯过程需要使用私钥去解密客戶端发來的经过证书公钥加密的随机数信息，是 HTTPS 加密通讯过程非常重要的文件，在配置 HTTPS 的時候要用到</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;名词解析&quot;&gt;&lt;a href=&quot;#名词解析&quot; class=&quot;headerlink&quot; title=&quot;名词解析&quot;&gt;&lt;/a&gt;名词解析&lt;/h3&gt;&lt;h5 id=&quot;WSGI&quot;&gt;&lt;a href=&quot;#WSGI&quot; class=&quot;headerlink&quot; title=&quot;WSGI&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="Flask" scheme="https://sssmeb.github.io/tags/Flask/"/>
    
      <category term="uwsgi" scheme="https://sssmeb.github.io/tags/uwsgi/"/>
    
      <category term="Nginx" scheme="https://sssmeb.github.io/tags/Nginx/"/>
    
      <category term="Python" scheme="https://sssmeb.github.io/tags/Python/"/>
    
  </entry>
  
</feed>
